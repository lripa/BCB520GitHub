[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Welcome to Lucas’ GitHub!",
    "section": "",
    "text": "Hi, welcome to Lucas Ripa’s GitHub.\nI’m an agricultural engineer from Chile who came to the US to pursue an MSc in entomology and made the decision to continue pursuing a PhD in entomology. I guess I like insects… My goal is to improve agricultural practices, finding ways to reduce inputs and maximize yields (lowering pests populations)."
  },
  {
    "objectID": "posts/Midterm/midterm.html",
    "href": "posts/Midterm/midterm.html",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "",
    "text": "The main goal of this midterm is to assess the University of Idaho’s performance regarding awarded grants and how we compare to other geographically close universities. The funding agencies are; The National Science Foundation, The National Institutes of Health, The Department of Energy, and The US Department of Agriculture.\nWe were provided with several data sets from 4 different funding agencies. A quick overview for each funding agency is provided below:\n1.- Department of Energy (DOE)\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\ntry({\n  DOE &lt;- read_xlsx(\"DOEawards.xlsx\")\n  \n  DOE_UI &lt;- DOE %&gt;% \n    dplyr::filter(Institution == 'Regents of the University of Idaho')\n  \n  DOE_UIFiltered &lt;- DOE_UI %&gt;%\n    select(Title, Institution, PI, Status, `Program Office`, `Start Date`, `End Date`, `Amount Awarded to Date`)\n  \n  # Display the table\n  knitr::kable(head(DOE_UIFiltered))\n}, silent = TRUE)\n\n\nNew names:\n• `` -&gt; `...27`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInstitution\nPI\nStatus\nProgram Office\nStart Date\nEnd Date\nAmount Awarded to Date\n\n\n\n\nNuclear Theory at the University of Idaho\nRegents of the University of Idaho\nSammarruca, Francesca\nActive\nOffice of Nuclear Physics\n12/01/2021\n11/30/2024\n1812000\n\n\nConverting methoxy groups on lignin-derived aromatics from a toxic hurdle to a useful resource: a systems-driven approach\nRegents of the University of Idaho\nMarx, Christopher\nActive\nOffice of Biological & Environmental Research\n09/01/2021\n08/31/2024\n1404162\n\n\nIntegrative Imaging of Plant Roots during Symbiosis with Mycorrhizal Fungi\nRegents of the University of Idaho\nVasdekis, Andreas\nActive\nOffice of Biological & Environmental Research\n08/15/2021\n08/14/2024\n1519359\n\n\nNutrient and Fine Sediment Transport Driven by Perturbations in River Bed Movement\nRegents of the University of Idaho\nYager, Elowyn\nActive\nOffice of Biological & Environmental Research\n09/01/2020\n08/31/2024\n603903\n\n\n\n\n\n2.- The National Institutes of Health (NIH)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Attempt to read the Excel file and process it\ntry({\n  # Read the Excel file into a data frame\n  NIH &lt;- read_xlsx(\"NIH.xlsx\")\n  \n  # Filter and select specific columns from the NSF data frame\n  NIH_Filtered &lt;- NIH %&gt;%\n    select(contact_pi_name, award_amount, budget_start)\n  \n  # Display the table using knitr::kable\n  knitr::kable(head(NIH_Filtered))\n}, silent = TRUE)\n\n\n\n\n\ncontact_pi_name\naward_amount\nbudget_start\n\n\n\n\nMCGUIRE, MICHELLE KAY\n2354626\n2024-03-11T12:03:00Z\n\n\nWILLIAMS, JANET E.\n461621\n2024-01-15T12:01:00Z\n\n\nCHEN, YIMIN\n162320\n2024-01-15T12:01:00Z\n\n\nLANE, GINNY\n153322\n2024-01-15T12:01:00Z\n\n\nMCGUIRE, MICHELLE KAY\n300000\n2024-01-15T12:01:00Z\n\n\nMCGUIRE, MICHELLE KAY\n946131\n2024-01-15T12:01:00Z\n\n\n\n\n\n3.- Department of Agriculture (NIFA)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(knitr)\nUSDA_UI  &lt;- read.csv(\"USDAtoUI.csv\")\nknitr::kable(head(USDA_UI))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAward.Date\nGrant.Number\nProposal.Number\nGrant.Title\nState.Name\nGrantee.Name\nAward.Dollars\nProgram.Name\nProgram.Area.Name\n\n\n\n\n2010-09-30\n2010-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n7495\nN/A\nN/A\n\n\n2009-09-30\n2009-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n6813\nN/A\nN/A\n\n\n2008-09-30\n2008-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n8524\nN/A\nN/A\n\n\n2003-09-30\n2003-48604-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n1097\nN/A\nN/A\n\n\n2010-09-30\n2010-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n11997\nN/A\nN/A\n\n\n2009-09-30\n2009-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n14990\nN/A\nN/A\n\n\n\n\n\n4.- The National Science Foundation (NSF)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Attempt to read the Excel file and process it\ntry({\n  # Read the Excel file into a data frame\n  NSF &lt;- read_xlsx(\"NSFtoUI.xlsx\")\n  \n  # Filter and select specific columns from the NSF data frame\n  NSF_Filtered &lt;- NSF %&gt;%\n    select(pdPIName, startDate, expDate, estimatedTotalAmt)\n  \n  # Display the table using knitr::kable\n  knitr::kable(head(NSF_Filtered))\n}, silent = TRUE)\n\n\n\n\n\npdPIName\nstartDate\nexpDate\nestimatedTotalAmt\n\n\n\n\nDave Lien\n04/01/2024\n03/31/2026\n628415.00\n\n\nKristopher V Waynant\n04/01/2024\n03/31/2027\n456051.00\n\n\nTara Hudiburg\n03/01/2024\n08/31/2025\n1000000.00\n\n\nJulie M Amador\n12/01/2023\n11/30/2027\n1179977.00\n\n\nEsteban A Hernandez Vargas\n11/01/2023\n10/31/2025\n250000.00\n\n\nLilian Alessa\n10/01/2023\n09/30/2027\n2435509.00"
  },
  {
    "objectID": "posts/Midterm/midterm.html#preamble",
    "href": "posts/Midterm/midterm.html#preamble",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "",
    "text": "The main goal of this midterm is to assess the University of Idaho’s performance regarding awarded grants and how we compare to other geographically close universities. The funding agencies are; The National Science Foundation, The National Institutes of Health, The Department of Energy, and The US Department of Agriculture.\nWe were provided with several data sets from 4 different funding agencies. A quick overview for each funding agency is provided below:\n1.- Department of Energy (DOE)\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\ntry({\n  DOE &lt;- read_xlsx(\"DOEawards.xlsx\")\n  \n  DOE_UI &lt;- DOE %&gt;% \n    dplyr::filter(Institution == 'Regents of the University of Idaho')\n  \n  DOE_UIFiltered &lt;- DOE_UI %&gt;%\n    select(Title, Institution, PI, Status, `Program Office`, `Start Date`, `End Date`, `Amount Awarded to Date`)\n  \n  # Display the table\n  knitr::kable(head(DOE_UIFiltered))\n}, silent = TRUE)\n\n\nNew names:\n• `` -&gt; `...27`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInstitution\nPI\nStatus\nProgram Office\nStart Date\nEnd Date\nAmount Awarded to Date\n\n\n\n\nNuclear Theory at the University of Idaho\nRegents of the University of Idaho\nSammarruca, Francesca\nActive\nOffice of Nuclear Physics\n12/01/2021\n11/30/2024\n1812000\n\n\nConverting methoxy groups on lignin-derived aromatics from a toxic hurdle to a useful resource: a systems-driven approach\nRegents of the University of Idaho\nMarx, Christopher\nActive\nOffice of Biological & Environmental Research\n09/01/2021\n08/31/2024\n1404162\n\n\nIntegrative Imaging of Plant Roots during Symbiosis with Mycorrhizal Fungi\nRegents of the University of Idaho\nVasdekis, Andreas\nActive\nOffice of Biological & Environmental Research\n08/15/2021\n08/14/2024\n1519359\n\n\nNutrient and Fine Sediment Transport Driven by Perturbations in River Bed Movement\nRegents of the University of Idaho\nYager, Elowyn\nActive\nOffice of Biological & Environmental Research\n09/01/2020\n08/31/2024\n603903\n\n\n\n\n\n2.- The National Institutes of Health (NIH)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Attempt to read the Excel file and process it\ntry({\n  # Read the Excel file into a data frame\n  NIH &lt;- read_xlsx(\"NIH.xlsx\")\n  \n  # Filter and select specific columns from the NSF data frame\n  NIH_Filtered &lt;- NIH %&gt;%\n    select(contact_pi_name, award_amount, budget_start)\n  \n  # Display the table using knitr::kable\n  knitr::kable(head(NIH_Filtered))\n}, silent = TRUE)\n\n\n\n\n\ncontact_pi_name\naward_amount\nbudget_start\n\n\n\n\nMCGUIRE, MICHELLE KAY\n2354626\n2024-03-11T12:03:00Z\n\n\nWILLIAMS, JANET E.\n461621\n2024-01-15T12:01:00Z\n\n\nCHEN, YIMIN\n162320\n2024-01-15T12:01:00Z\n\n\nLANE, GINNY\n153322\n2024-01-15T12:01:00Z\n\n\nMCGUIRE, MICHELLE KAY\n300000\n2024-01-15T12:01:00Z\n\n\nMCGUIRE, MICHELLE KAY\n946131\n2024-01-15T12:01:00Z\n\n\n\n\n\n3.- Department of Agriculture (NIFA)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(knitr)\nUSDA_UI  &lt;- read.csv(\"USDAtoUI.csv\")\nknitr::kable(head(USDA_UI))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAward.Date\nGrant.Number\nProposal.Number\nGrant.Title\nState.Name\nGrantee.Name\nAward.Dollars\nProgram.Name\nProgram.Area.Name\n\n\n\n\n2010-09-30\n2010-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n7495\nN/A\nN/A\n\n\n2009-09-30\n2009-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n6813\nN/A\nN/A\n\n\n2008-09-30\n2008-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n8524\nN/A\nN/A\n\n\n2003-09-30\n2003-48604-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n1097\nN/A\nN/A\n\n\n2010-09-30\n2010-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n11997\nN/A\nN/A\n\n\n2009-09-30\n2009-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n14990\nN/A\nN/A\n\n\n\n\n\n4.- The National Science Foundation (NSF)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Attempt to read the Excel file and process it\ntry({\n  # Read the Excel file into a data frame\n  NSF &lt;- read_xlsx(\"NSFtoUI.xlsx\")\n  \n  # Filter and select specific columns from the NSF data frame\n  NSF_Filtered &lt;- NSF %&gt;%\n    select(pdPIName, startDate, expDate, estimatedTotalAmt)\n  \n  # Display the table using knitr::kable\n  knitr::kable(head(NSF_Filtered))\n}, silent = TRUE)\n\n\n\n\n\npdPIName\nstartDate\nexpDate\nestimatedTotalAmt\n\n\n\n\nDave Lien\n04/01/2024\n03/31/2026\n628415.00\n\n\nKristopher V Waynant\n04/01/2024\n03/31/2027\n456051.00\n\n\nTara Hudiburg\n03/01/2024\n08/31/2025\n1000000.00\n\n\nJulie M Amador\n12/01/2023\n11/30/2027\n1179977.00\n\n\nEsteban A Hernandez Vargas\n11/01/2023\n10/31/2025\n250000.00\n\n\nLilian Alessa\n10/01/2023\n09/30/2027\n2435509.00"
  },
  {
    "objectID": "posts/Midterm/midterm.html#data-dictionary-table",
    "href": "posts/Midterm/midterm.html#data-dictionary-table",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "Data Dictionary table",
    "text": "Data Dictionary table\nIn general all the data sets shares the same variables with different names. The most commonly used ones are summarized in the table below:\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(knitr)\ndatatable  &lt;- read_xlsx(\"DataDictionary.xlsx\")\nknitr::kable(head(datatable))\n\n\n\n\n\nAttribute\nDescription\nType\n\n\n\n\nPI\nPrincipal Investigator\nCharacter\n\n\nInstitution\nUniversity/instiution name\nCharacter\n\n\nStart date\nDate where the award started\nDate\n\n\nEnd date\nDate where the award ends\nDate\n\n\nCode\nInternal code of the award\nNumeric\n\n\nAmount\nAmount of money awarded\nNumeric"
  },
  {
    "objectID": "posts/Midterm/midterm.html#question-1",
    "href": "posts/Midterm/midterm.html#question-1",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "QUESTION 1:",
    "text": "QUESTION 1:\nProvide a visualization that shows our active awards from each sponsor. I need to see their start date and end date, the amount of the award, and the name of the Principal Investigator. I’m really interested in seeing how far into the future our current portfolio will exist. Are there a bunch of awards about to expire? Are there a bunch that just got funded and will be active for a while? Does this vary across sponsors?\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nfunding_data &lt;- read_xlsx(\"UIawards.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Count the unique PIs per agency\npi_count_per_agency &lt;- funding_data %&gt;%\n  group_by(Agency) %&gt;%\n  summarise(PI_Count = n_distinct(PI))\n\n# Filter for the specific agencies if the dataset contains more agencies\npi_count_per_agency &lt;- pi_count_per_agency %&gt;%\n  filter(Agency %in% c(\"NSF\", \"NIH\", \"USDA\", \"DOE\"))\n\n# Create the bar chart\nggplot(pi_count_per_agency, aes(x = Agency, y = PI_Count, fill = Agency)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Total number of PIs Per Agency in UofI recent history\",\n       x = \"Agency\",\n       y = \"Number of PIs\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\nIn general NSF seems to be the funding agency with the most PIs in UofI history. USDA and DOE seems to fund always the same PIs.\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# Read data from an Excel file\nUSDA10 &lt;- read_xlsx(\"USDA10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Convert start to Date objects\nUSDA10$start &lt;- as.Date(USDA10$start, format = \"%m/%d/%Y\")\n\n# Handle end date: Assuming you have only the year, create a Date object for December 31st of that year\nUSDA10$end &lt;- as.Date(paste0(USDA10$end, \"-12-31\"), format = \"%Y-%m-%d\")\n\n# Create the Gantt chart\nggplot(USDA10, aes(y = Agency, x = start, xend = end, yend = Agency)) +\n  geom_segment(size = 10, color = \"green\") + # Adjust the size as needed\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", limits = c(as.Date(\"2021-01-01\"), as.Date(\"2029-01-01\"))) +\n  labs(title = \"10 years of active USDA funding\",\n       x = \"Timeline\",\n       y = \"Agency\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 166 rows containing missing values (`geom_segment()`).\n\n\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Read data from an Excel file\nDOE10 &lt;- read_xlsx(\"DOE10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Convert start and end to Date objects\n# Assuming your Excel file has columns named 'start' and 'end'\nDOE10$start &lt;- as.Date(DOE10$start, format = \"%m/%d/%Y\")\nDOE10$end &lt;- as.Date(DOE10$end, format = \"%m/%d/%Y\")\n\n# Create the Gantt chart\nggplot(DOE10, aes(y = Agency, x = start, xend = end, yend = Agency)) +\n  geom_segment(size = 20, color = \"black\") + # Use linewidth instead of size\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", limits = c(as.Date(\"2021-01-01\"), as.Date(\"2029-01-01\"))) +\n  labs(title = \"10 years of active DOE funding\",\n       x = \"Timeline\",\n       y = \"Agency\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning: Removed 1 rows containing missing values (`geom_segment()`).\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(RColorBrewer)\n\n\n# Aggregate data to get the total amount per PI and filter out amounts smaller than 200000\ntotal_amount_per_PI &lt;- DOE10 %&gt;%\n  group_by(PI) %&gt;%\n  summarise(TotalAmount = sum(Amount, na.rm = TRUE)) %&gt;%\n  filter(TotalAmount &gt;= 200000) %&gt;%  # Filter step added here\n  arrange(desc(TotalAmount))\n\nggplot(total_amount_per_PI, aes(x = PI, y = TotalAmount / 1e6)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"NSF Total Funding per PI in the Last 10 Years\",\n       y = \"Total Funding Amount (USD Millions)\",\n       x = \"Principal Investigator\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate X-axis labels for readability\n\n\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Read data from an Excel file\nNSF10 &lt;- read_xlsx(\"NSF10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Convert start and end to Date objects\n# Assuming your Excel file has columns named 'start' and 'end'\nNSF10$start &lt;- as.Date(NSF10$start, format = \"%m/%d/%Y\")\nNSF10$end &lt;- as.Date(NSF10$end, format = \"%m/%d/%Y\")\n\n# Create the Gantt chart\nggplot(NSF10, aes(y = Agency, x = start, xend = end, yend = Agency)) +\n  geom_segment(size = 20, color = \"red\") + # Use linewidth instead of size\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", limits = c(as.Date(\"2021-01-01\"), as.Date(\"2029-01-01\"))) +\n  labs(title = \"10 years of active NSF funding\",\n       x = \"Timeline\",\n       y = \"Agency\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning: Removed 81 rows containing missing values (`geom_segment()`).\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(RColorBrewer)\n\nNSF10 &lt;- read_xlsx(\"NSF10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Aggregate data to get the total amount per PI and filter out amounts smaller than 200000\ntotal_amount_per_PI &lt;- NSF10 %&gt;%\n  group_by(PI) %&gt;%\n  summarise(TotalAmount = sum(Amount, na.rm = TRUE)) %&gt;%\n  filter(TotalAmount &gt;= 200000) %&gt;%  # Filter step added here\n  arrange(desc(TotalAmount))\n\nggplot(total_amount_per_PI, aes(x = PI, y = TotalAmount / 1e6)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"NSF Total Funding per PI in the Last 10 Years\",\n       y = \"Total Funding Amount (USD Millions)\",\n       x = \"Principal Investigator\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate X-axis labels for readability\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(lubridate)\n\ndf &lt;- read_xlsx(\"UIawards.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Assuming your dataset is named df\n# Clean 'Agency' data (remove leading/trailing spaces, check for case sensitivity)\ndf$Agency &lt;- as.character(trimws(df$Agency))\n\n# Convert 'start' and 'end' columns to Date format\ndf$start &lt;- as.Date(df$start, format = \"%Y-%m-%d\")\ndf$end &lt;- as.Date(df$end, format = \"%Y-%m-%d\")\n\n# Create a timeline that spans 10 years back and 10 years forward from today\ntimeline_start &lt;- Sys.Date() - years(10)\ntimeline_end &lt;- Sys.Date() + years(10)\n\n# Plotting\nggplot(df, aes(y = factor(Agency, levels = unique(Agency)), x = start, xend = end, yend = factor(Agency, levels = unique(Agency)))) +\n  geom_segment(size = 20, color = \"blue\") +  # Adjust size and color as needed\n  scale_x_date(limits = c(timeline_start, timeline_end), date_breaks = \"1 year\", date_labels = \"%Y\") +\n  labs(title = \"Project Timeline\",\n       x = \"Year\",\n       y = \"Agency\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 7),\n        panel.grid.major.x = element_line(color = \"grey80\"),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank())\n\n\nWarning: Removed 1353 rows containing missing values (`geom_segment()`).\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(RColorBrewer)\n\nNIH10 &lt;- read_xlsx(\"NIH10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Aggregate data to get the total amount per PI and filter out amounts smaller than 200000\ntotal_amount_per_PI &lt;- NIH10 %&gt;%\n  group_by(PI) %&gt;%\n  summarise(TotalAmount = sum(Amount, na.rm = TRUE)) %&gt;%\n  filter(TotalAmount &gt;= 200000) %&gt;%  # Filter step added here\n  arrange(desc(TotalAmount))\n\nggplot(total_amount_per_PI, aes(x = PI, y = TotalAmount / 1e6)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"NSF Total Funding per PI in the Last 10 Years\",\n       y = \"Total Funding Amount (USD Millions)\",\n       x = \"Principal Investigator\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate X-axis labels for readability\n\n\n\n\n\nAccording to the plotted data, NSF and NIH appear to have secured grants into the furthest future, (2028-2029)."
  },
  {
    "objectID": "posts/Midterm/midterm.html#question-2",
    "href": "posts/Midterm/midterm.html#question-2",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "QUESTION 2:",
    "text": "QUESTION 2:\nWhat is the proportional representation of new awards to the UI from these various sources over the past 5 to 10 years? Are there any trends that are encouraging or discouraging?"
  },
  {
    "objectID": "posts/Midterm/midterm.html#question-3",
    "href": "posts/Midterm/midterm.html#question-3",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "QUESTION 3:",
    "text": "QUESTION 3:\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nBU &lt;- read_xlsx(\"NIH.xlsx\")\n\n# Use 'BU' instead of 'df' for operations\nselected_universities &lt;- BU %&gt;%\n  filter(organization.org_name %in% c(\"BOISE STATE UNIVERSITY\", \"UNIVERSITY OF IDAHO\")) %&gt;%\n  group_by(organization.org_name) %&gt;%\n  summarise(total_award_amount = sum(award_amount, na.rm = TRUE))\n\n# Create the bar chart\nggplot(selected_universities, aes(x = organization.org_name, y = total_award_amount, fill = organization.org_name)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Total Award Amount by University NIH\",\n       x = \"University\",\n       y = \"Total Award Amount NIH\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"BOISE STATE UNIVERSITY\" = \"blue\", \"UNIVERSITY OF IDAHO\" = \"gold\"))\n\n\n\n\n\nHow is UI performing with these sponsors when compared to the following peer institutions?\nBoise State University Idaho State University Montana State University University of Montana Washington State University Note that “performing” can mean a variety of different things. You must choose your metrics of performance and justify them."
  },
  {
    "objectID": "posts/Midterm/midterm.html#conclusions",
    "href": "posts/Midterm/midterm.html#conclusions",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "Conclusions",
    "text": "Conclusions\nSummary Summarize your results. What new questions have emerged as a result of your visualizations? What interesting next steps have emerged?"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "“Welcome!”",
    "section": "",
    "text": "Green lacewing family Chrysopidae"
  },
  {
    "objectID": "posts/Winter Sports/index.html",
    "href": "posts/Winter Sports/index.html",
    "title": "Hockey DataViz (A5)",
    "section": "",
    "text": "Demonstrate that you can manipulate tabular data to facilitate different visualization tasks. The minimum skills are FILTERING, SELECTING, and SUMMARIZING, all while GROUPING these operations as dictated by your data.\nDemonstrate that you can use tabular data to explore, analyze, and choose the most appropriate visualization idioms given a specific motivating question.\nDemonstrate that you can Find, Access, and Integrate additional data in order to fully address the motivating question."
  },
  {
    "objectID": "posts/Winter Sports/index.html#learning-objectives",
    "href": "posts/Winter Sports/index.html#learning-objectives",
    "title": "Hockey DataViz (A5)",
    "section": "",
    "text": "Demonstrate that you can manipulate tabular data to facilitate different visualization tasks. The minimum skills are FILTERING, SELECTING, and SUMMARIZING, all while GROUPING these operations as dictated by your data.\nDemonstrate that you can use tabular data to explore, analyze, and choose the most appropriate visualization idioms given a specific motivating question.\nDemonstrate that you can Find, Access, and Integrate additional data in order to fully address the motivating question."
  },
  {
    "objectID": "posts/Winter Sports/index.html#scenario",
    "href": "posts/Winter Sports/index.html#scenario",
    "title": "Hockey DataViz (A5)",
    "section": "SCENARIO",
    "text": "SCENARIO\nFor the purposes of this exercise, let’s set the 2024 NHL draft order using the Tankathon Simulator. The NHL uses a lottery system in which the teams lowest in the standings have the highest odds of getting the first overall pick. This year the Canucks are at the top of the league, and positioned to have the 31st overall pick. According to the simulator, Calgary will pick at number 2 (which is very valuable!), and the Canuck’s pick at 31.\nHere is the question:\nWas the trade worth it? This trade has a high likelihood of becoming what we call a rental. Elias Lindholm is on an expiring contract, meaning Vancouver is guaranteed to hold his contract only through the end of the season. They might be able to extend him, but that depends on the salary cap.\nMeanwhile, Calgary can draft a player at position 31, who may or may not turn out to be of equal or greater value than Lindholm.\nWas the trade worth it? Did Vancouver or Calgary “win” the trade?\nCan we make some visualizations that help us answer this question?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#the-data",
    "href": "posts/Winter Sports/index.html#the-data",
    "title": "Hockey DataViz (A5)",
    "section": "THE DATA",
    "text": "THE DATA\nHow can we evaluate whether trading a first round pick for a rental player is a good idea? One approach is to look at the historical performance of players from various draft positions.\n\nCodelibrary(tidyverse)\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nCodelibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readxl)\n\n\n\nCodeNHLDraft&lt;-read.csv(\"NHLDraft.csv\")\nNHLDictionary&lt;-read_excel(\"NHLDictionary.xlsx\")\nNHLStats&lt;-read.csv(\"NHLdraftstats.csv\")\nhead(NHLDraft)\n\n  X draftyear      name round overall pickinRound height weight position\n1 1      2001 Drew Fata     3      86          23     73    209  Defense\n2 2      2001 Drew Fata     3      86          23     73    209  Defense\n3 3      2001 Drew Fata     3      86          23     73    209  Defense\n4 4      2001 Drew Fata     3      86          23     73    209  Defense\n5 5      2001 Drew Fata     3      86          23     73    209  Defense\n6 6      2001 Drew Fata     3      86          23     73    209  Defense\n  playerId postdraft NHLgames\n1  8469535         0        0\n2  8469535         1        0\n3  8469535         2        0\n4  8469535         4        0\n5  8469535         5        3\n6  8469535        10        0\n\nCodeknitr::kable(NHLDictionary)\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\ndraftyear\nOrdinal\nCalendar year in which the player was drafted into the NHL.\n\n\nname\nItem\nFull name of the player.\n\n\nround\nOrdinal\nRound in which the player was drafted (1 to 7).\n\n\noverall\nOrdinal\nOverall draft position of the player (1 to 224)\n\n\npickinRound\nOrdinal\nPosition in which the player was drafted in their round (1 to 32).\n\n\nheight\nQuantitative\nPlayer height in inches.\n\n\nweight\nQuantitative\nPlayer weight in pounds.\n\n\nposition\nCategorical\nPlayer position (Forward, Defense, Goaltender)\n\n\nplayerId\nItem\nUnique ID (key) assigned to each player.\n\n\npostdraft\nOrdinal\nNumber of seasons since being drafted (0 to 20).\n\n\nNHLgames\nQuantitative\nNumber of games played in the NHL in that particular season (regular season is 82 games, playoffs are up to 28 more).\n\n\n\n\n\nIn this case, we have a dataframe with all the drafted players from 2000-2018, their position, their draft year and position, and then rows for each season since being drafted (postdraft). The key variable here is NHLgames, which tells us how many games they played in the NHL each season since being drafted. Whether drafted players even make the NHL, and how many games they play, might be a good proxy to understand the value of a draft pick we just traded away."
  },
  {
    "objectID": "posts/Winter Sports/index.html#simple-scatterplot",
    "href": "posts/Winter Sports/index.html#simple-scatterplot",
    "title": "Hockey DataViz (A5)",
    "section": "SIMPLE SCATTERPLOT",
    "text": "SIMPLE SCATTERPLOT\nOne thing to realize about professional hockey is that it is pretty rare for a player to play in the NHL right after being drafted. Players get drafted when they are 18 years old, and they usually play in the juniors, minor leagues, or the NCAA for a bit to further develop.\nLet’s use a scatterplot to visualize this phenomenon with the most recent draft classes.\n\nCodedraft2022&lt;-NHLDraft%&gt;%\n  filter(draftyear==2022 & postdraft==0)\n\n\n\n\nggplot(draft2022, aes(x=round, y=NHLgames))+\n  geom_point()\n\n\n\n\nAs you can see, the players drafted in June of 2022 didn’t play much last season. There are few things wrong with this visualization, however:\n\n\nOverplotting. All those points on the y=0 line represent about 32 players each. Can you think of a way that adding extra channels might help? Violin plots could work or jitter plots (see examples below). Also, colors will aid separate rounds.\n\n\n\nCodelibrary(ggplot2)\n\nggplot(draft2022, aes(x=factor(round), y=NHLgames, fill=factor(round))) +\n  geom_violin(trim=FALSE) +\n  labs(title = \"NHL Games by Draft Round\",\n       x = \"Draft Round\",\n       y = \"NHL Games\") +\n  theme_light() +\n  scale_fill_brewer(palette=\"Pastel1\") + \n  theme(axis.text.x = element_text(angle=45, hjust=1))\n\n\n\nCodelibrary(ggplot2)\n\nggplot(draft2022, aes(x=factor(round), y=NHLgames, color=factor(round))) +\n  geom_jitter(width = 0.2, height = 0, alpha=1) +\n  labs(title = \"NHL Games by Draft Round (Jitter Plot)\",\n       x = \"Draft Round\",\n       y = \"NHL Games\") +\n  theme_light() +\n  scale_color_brewer(palette=\"Set3\") + \n  theme(axis.text.x = element_text(angle=0, hjust=1)) \n\n\n\n\n\n\nLabelling. Can we create a solid figure caption and better axis labels for this figure? In your caption, please specify the task(s) the visualizaiton is intended to facilitate, as well as the marks, channels, and key-value pairs used. Y axis label: Number of NHL games played, X: Draft Round, channels color and shape.\n\nCodelibrary(ggplot2)\n\nggplot(draft2022, aes(x=factor(round), y=NHLgames, color=factor(round), shape=factor(round))) +\n  geom_jitter(width = 0.2, height = 0, alpha=1) +\n  labs(title = \"NHL Games by Draft Round (Jitter Plot)\",\n       x = \"Draft Round Number\",\n       y = \"Number of NHL games played\") +\n  theme_light() +\n  scale_color_brewer(palette=\"Set3\") +\n  scale_shape_manual(values=c(1:30)) + \n  theme(axis.text.x = element_text(angle=0, hjust=1))\n\n\n\n\n\nKey-Value pairs: Looks like we are using “round” as a continuous variable. Can we change this to an ordered factor?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#expanded-scatterplot",
    "href": "posts/Winter Sports/index.html#expanded-scatterplot",
    "title": "Hockey DataViz (A5)",
    "section": "EXPANDED SCATTERPLOT",
    "text": "EXPANDED SCATTERPLOT\nThe data from the most recent drafts aren’t really helpful for our question. Let’s go back in time and use a draft year that has had some time to develop and reach their potential. How about 2018?\n\nCodedraft2018&lt;-NHLDraft%&gt;%\n  filter(draftyear==2018 & postdraft&lt;6) \n\n# wondering why I've filtered postdraft to be less than 6?  Try removing that filter to see what happens.\n\nggplot(draft2018, aes(x=round, y=NHLgames))+\n  geom_point()\n\n\n\nCodelibrary(ggplot2)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nHmmm… in addition to the problem of overplotting, we’ve got an additional issue here. We actually have two keys and one attribute. The attribute is NHLgames, and the keys are round and postdraft, but we are only using round.\nPostdraft indicates the number of seasons after being drafted. We have several choices here. We can make a visualization that uses both keys, or we can somehow summarize the data for one of the keys.\nFor example, let’s say we just wanted to know the TOTAL number of NHL games played since being drafted.\n\nCodedrafttot2018&lt;- draft2018%&gt;%\n  group_by(playerId, round, overall, position, name)%&gt;%\n  summarise(totgames=sum(NHLgames))\n\n`summarise()` has grouped output by 'playerId', 'round', 'overall', 'position'.\nYou can override using the `.groups` argument.\n\nCodeggplot(drafttot2018, aes(x=round, y=totgames))+\n  geom_point()\n\n\n\n\nLook closely at the two graphs above. How are they different?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#stop-and-reflect",
    "href": "posts/Winter Sports/index.html#stop-and-reflect",
    "title": "Hockey DataViz (A5)",
    "section": "STOP AND REFLECT",
    "text": "STOP AND REFLECT\nI’ve been a bit sneaky up to this point. You’ve probably been focusing primarily on my (crappy) visualizations. That’s fine, but let’s think about the manipulations to the TABULAR DATA I’ve had to perform.\nI’m using the Tidyverse to do these manipulations. I set up the original data frame to conform to the tidy data principles (every column is a variable, every row is an observation), which is pretty much the base form of how we’ve discussed Tabular Data in class.\nI’ve snuck in some functions that have allowed me to FILTER, GROUP, and SUMMARIZE the data, often creating new dataframes as I do so. Hey, look! A handy cheatsheet for data transformation using the tidyverse!\nThese functions come from the dplyr package that gets installed as part of the tidyverse. The basic categories of actions are:\n\nmutate() adds new variables that are functions of existing variables\nselect() picks variables based on their names.\nfilter() picks cases based on their values.\nsummarise() reduces multiple values down to a single summary.\narrange() changes the ordering of the rows.\n\nAll of these work with group_by() so you can perform whichever operation on the groups that might be present in your data set.\nLet’s get back to improving our understanding of the relative value of NHL draft picks. The figure above considers a single draft class (2018), and shows the total number of NHL games all the players have accumulated, separating each draft round on an ordinal x axis.\nFine, I guess, but we still have to deal with overplotting, and think about whether a scatterplot really helps us accomplish our task. For this figure do the following:\n\n\nOverplotting. All those points on the y=0 line represent about 32 players each. Can you you think of a way that adding extra channels might help?\n\nLabelling. Can we create a solid figure caption and better axis labels for this figure? In your caption, please specify the task(s) the visualizaiton is intended to facilitate, as well as the marks, channels, and key-value pairs used.\n\nKey-Value pairs: Looks like we are using “round” as a continuous variable. Can we change this to an ordered factor?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#scatterplot-with-overall-draft-position",
    "href": "posts/Winter Sports/index.html#scatterplot-with-overall-draft-position",
    "title": "Hockey DataViz (A5)",
    "section": "SCATTERPLOT WITH OVERALL DRAFT POSITION",
    "text": "SCATTERPLOT WITH OVERALL DRAFT POSITION\nThis approach might yield a better match with the scatterplot idiom. What if we ignore draft round, and use the player’s overall draft position instead? It also might help us focus on our motivating question! What is the potential value of pick 31, and how does Elias Lindholm compare to that value?\n\nCodeggplot(drafttot2018, aes(x=overall, y=totgames))+\n  geom_point()\n\n\n\n\nFor this figure, address the following:\n\nWe are trying to address the notion of trading pick 31. How might you facilitate the task of evaluating picks in that range?\nCreate a caption and better axis labels for this figure.\nWhat if we wanted to use more than just the 2018 draft class?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#scatterplot-summary",
    "href": "posts/Winter Sports/index.html#scatterplot-summary",
    "title": "Hockey DataViz (A5)",
    "section": "SCATTERPLOT SUMMARY",
    "text": "SCATTERPLOT SUMMARY\nWe seem to be running into an issue in terms of overplotting. Scatterplots are great, but they work best for two quantitative attributes, and we have a situation with one or two keys and one quantitative attribute. The thing is, scatterplots can be very useful when part of our workflow involves modeling the data in some way. We’ll cover this kind of thing in future assignments, but just a bit of foreshadowing here:\n\nCodeggplot(drafttot2018, aes(x=round, y=totgames))+\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nAdding the smoothed line doesn’t eliminate the overplotting problem, but it does indicate that it exists. We’ll cover other potential solutions (such as box plots and violin plots) to this issue later in the course, when we get to the notions of faceting and data reduction.\nWhy not include all the data? A scatter plot with that many players (4775) isn’t going to be great. But we could plot some sort of polynomial model to get a sense of the relationship between draft position and NHL games. We’ll filter to the first 8 years of their career."
  },
  {
    "objectID": "posts/Winter Sports/index.html#conclusive-figure",
    "href": "posts/Winter Sports/index.html#conclusive-figure",
    "title": "Hockey DataViz (A5)",
    "section": "Conclusive Figure",
    "text": "Conclusive Figure\n\nCodeNHLdraftstats &lt;- read.csv(\"NHLdraftstats.csv\")\n\nlibrary(ggplot2)\n\nElias &lt;- NHLdraftstats %&gt;%\n  filter(name == \"Elias Lindholm\")\n\nggplot(NHLDraft, aes(x=postdraft, y=NHLgames)) +\n  geom_smooth(aes(color=as.factor(round)), se=FALSE, linetype=\"dashed\") +  \n  geom_smooth(data = Elias, aes(x=postdraft, y=NHLgames), se=FALSE, linetype=\"solid\", linewidth=2, color=\"orange\") +\n  labs(title = \"NHL Games by Post-Draft Position + Elias Performance (in orange)\",\n       x = \"Post-Draft Position\",\n       y = \"NHL Games\",\n       color = \"Round\") +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "posts/Winter Sports/index.html#divergence",
    "href": "posts/Winter Sports/index.html#divergence",
    "title": "Hockey DataViz (A5)",
    "section": "DIVERGENCE",
    "text": "DIVERGENCE\nEnough esoteric wandering. The original version of this assignment focused on the relative value of draft picks in the NHL. This version has a more specific question. What might picks in the range of pick 31 conceivably yield? How often do picks in that range yield players of Elias Lindholm’s value?\nI guess we’d better figure out what Elias Lindholm brings to the table.\nCan you find him in our existing data? Can you think of a way to highlight him in the context of number of games played? What other kinds of data might we need to fairly evaluate Lindholm and pick 31?\nYou will be surprised how these seemingly simple questions force you to explore the nuances of working with and visualizing tabular data."
  },
  {
    "objectID": "posts/Winter Sports/index.html#conclusion",
    "href": "posts/Winter Sports/index.html#conclusion",
    "title": "Hockey DataViz (A5)",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nBased on your visualizations, what would you advise regarding this trade proposal? Why?\nClearly, Elias Lindholm is an above average player, as shown it the graph above (NHL Games by Post-Draft Position + Elias Performance (in orange)). His rental should provide an immediate boost to the Canucks, considering his performance and experience. The trade seems favorable in the present. It’s important to consider that the chances for a pick 31 player to be extraordinary are extremely slim, so this supports the trade in favor of the Canucks."
  },
  {
    "objectID": "posts/MarksChannels/index.html",
    "href": "posts/MarksChannels/index.html",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "Code\nlibrary(readxl)\nWeevils &lt;- read_excel(\"~/Mi unidad/Uidaho/Clases/PhD/Spring 2024/BCB 520/Data/Weevils.xlsx\")\nhead(Weevils)\n\n\n# A tibble: 6 × 9\n  Treatment Replicate `Insecticide Name` Before `7 dpa` `14 dpa` `21 dpa`\n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1         0         1 Control                11       3        5        2\n2         0         2 Control                 4       4        4        3\n3         0         3 Control                16       6        7        3\n4         0         4 Control                 5       3        1        3\n5         0         5 Control                10       6        7        4\n6         0         6 Control                 2       5        2        4\n# ℹ 2 more variables: `28 dpa` &lt;dbl&gt;, `35 dpa` &lt;dbl&gt;\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nBmeans &lt;-Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE), AVG2 = mean(`14 dpa`, na.rm = TRUE), AVG3 = mean(`21 dpa`, na.rm = TRUE), AVG4 = mean(`28 dpa`, na.rm = TRUE), AVG5 = mean(`35 dpa`, na.rm = TRUE) )\nlibrary(ggplot2)\n\n\n\n\n\nThis figure uses different colors to make clear the difference between treatments. As the concentration of the experimental sample increases, the hue of the blue color increases as well making sense (to me).\n\n\n\n\n\nCode\nlibrary(tidyverse)\nBmeans &lt;-Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE), AVG2 = mean(`14 dpa`, na.rm = TRUE), AVG3 = mean(`21 dpa`, na.rm = TRUE), AVG4 = mean(`28 dpa`, na.rm = TRUE), AVG5 = mean(`35 dpa`, na.rm = TRUE) )\nlibrary(ggplot2)\nmy_colors &lt;- c(\"green\", \"cyan\", \"blue\", \"darkblue\", \"gold\", \"black\")\n\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant before treatments\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\nThis figure violates the channel correct use, since it uses the same color for every treatment, still is possible to understand what is going on but it takes significantly more time.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG)) +\n  geom_bar(stat = \"identity\", fill = \"black\") +\n  labs(title = \"Mean weevils per plant before treatments\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#section",
    "href": "posts/MarksChannels/index.html#section",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "Code\nlibrary(readxl)\nWeevils &lt;- read_excel(\"~/Mi unidad/Uidaho/Clases/PhD/Spring 2024/BCB 520/Data/Weevils.xlsx\")\nhead(Weevils)\n\n\n# A tibble: 6 × 9\n  Treatment Replicate `Insecticide Name` Before `7 dpa` `14 dpa` `21 dpa`\n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1         0         1 Control                11       3        5        2\n2         0         2 Control                 4       4        4        3\n3         0         3 Control                16       6        7        3\n4         0         4 Control                 5       3        1        3\n5         0         5 Control                10       6        7        4\n6         0         6 Control                 2       5        2        4\n# ℹ 2 more variables: `28 dpa` &lt;dbl&gt;, `35 dpa` &lt;dbl&gt;\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nBmeans &lt;-Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE), AVG2 = mean(`14 dpa`, na.rm = TRUE), AVG3 = mean(`21 dpa`, na.rm = TRUE), AVG4 = mean(`28 dpa`, na.rm = TRUE), AVG5 = mean(`35 dpa`, na.rm = TRUE) )\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-1",
    "href": "posts/MarksChannels/index.html#figure-1",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "This figure uses different colors to make clear the difference between treatments. As the concentration of the experimental sample increases, the hue of the blue color increases as well making sense (to me)."
  },
  {
    "objectID": "posts/MarksChannels/index.html#section-1",
    "href": "posts/MarksChannels/index.html#section-1",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nBmeans &lt;-Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE), AVG2 = mean(`14 dpa`, na.rm = TRUE), AVG3 = mean(`21 dpa`, na.rm = TRUE), AVG4 = mean(`28 dpa`, na.rm = TRUE), AVG5 = mean(`35 dpa`, na.rm = TRUE) )\nlibrary(ggplot2)\nmy_colors &lt;- c(\"green\", \"cyan\", \"blue\", \"darkblue\", \"gold\", \"black\")\n\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant before treatments\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-2",
    "href": "posts/MarksChannels/index.html#figure-2",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "This figure violates the channel correct use, since it uses the same color for every treatment, still is possible to understand what is going on but it takes significantly more time.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG)) +\n  geom_bar(stat = \"identity\", fill = \"black\") +\n  labs(title = \"Mean weevils per plant before treatments\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-3",
    "href": "posts/MarksChannels/index.html#figure-3",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 3",
    "text": "Figure 3\nThis figure uses different colors and marks (dots) to make clear the difference between treatments.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG5, group = 1, color = `Insecticide Name`)) +\n  geom_line() +\n  geom_point() + # Adds points to the line graph for clarity\n  scale_color_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant 35 DPA\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-4",
    "href": "posts/MarksChannels/index.html#figure-4",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 4",
    "text": "Figure 4\nA thick line, no color difference, no marks in between treatments, makes difficult to separate them. Same channel for everything.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG5, group = 1)) +\n  geom_line(size = 30, color = \"black\") \n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nCode\n  labs(title = \"Mean weevils per plant 35 DPA\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))\n\n\nNULL"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-5",
    "href": "posts/MarksChannels/index.html#figure-5",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 5",
    "text": "Figure 5\nStandard Error of the Mean (SEM), and bars for each treatment are presented using different channels. They are easily distinguishable between each other.\n\n\nCode\nlibrary(tidyverse)\nBmeans &lt;- Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE),\n            AVG2 = mean(`14 dpa`, na.rm = TRUE),\n            AVG3 = mean(`21 dpa`, na.rm = TRUE),\n            AVG4 = mean(`28 dpa`, na.rm = TRUE),\n            AVG5 = mean(`35 dpa`, na.rm = TRUE),\n            SD_14dpa = sd(`14 dpa`, na.rm = TRUE), \n            N_14dpa = sum(!is.na(`14 dpa`))) %&gt;% \n  mutate(SEM_14dpa = SD_14dpa / sqrt(N_14dpa)) \nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG2, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = AVG2 - SEM_14dpa, ymax = AVG2 + SEM_14dpa), width = 0.2) +\n  scale_fill_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant at 14 dpa\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-6",
    "href": "posts/MarksChannels/index.html#figure-6",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 6",
    "text": "Figure 6\nStandard Error of the Mean (SEM), and bars for each treatment shares the same channels. They are hardly distinguishable between each other.\n\n\nCode\nlibrary(tidyverse)\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG2, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = AVG2 - SEM_14dpa, ymax = AVG2 + SEM_14dpa, color = `Insecticide Name`), \n                width = 1, size = 3) +\n  scale_fill_manual(values = my_colors) +\n  scale_color_manual(values = my_colors) + \n  labs(title = \"Mean weevils per plant at 14 dpa\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-7",
    "href": "posts/MarksChannels/index.html#figure-7",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 7",
    "text": "Figure 7\nAs we compare the insecticide treatments with the control, this figure clearly depicts the differences between them and the control, using different channels,\n\n\nCode\nlibrary(tidyverse)\n\nBmeans &lt;- Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE),\n            AVG2 = mean(`14 dpa`, na.rm = TRUE),\n            AVG3 = mean(`21 dpa`, na.rm = TRUE),\n            AVG4 = mean(`28 dpa`, na.rm = TRUE),\n            AVG5 = mean(`35 dpa`, na.rm = TRUE),\n            SD_35dpa = sd(`35 dpa`, na.rm = TRUE),  # Calculate SD for 35 dpa\n            N_35dpa = sum(!is.na(`35 dpa`))) %&gt;%  # Count non-NA values for 35 dpa\n  mutate(SEM_35dpa = SD_35dpa / sqrt(N_35dpa))  # Calculate SEM for 35 dpa\n\n# Assuming my_colors is already defined\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG5, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = AVG5 - SEM_35dpa, ymax = AVG5 + SEM_35dpa), width = 0.2) +\n  scale_fill_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant at 35 dpa\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-8",
    "href": "posts/MarksChannels/index.html#figure-8",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 8",
    "text": "Figure 8\nHere, I’m using the same data at 35 dpa, but the scale of the Y-axis is incorrect. The same channels are used for everything without any markers for separability, resulting in an awful graph.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG5, group = 1)) +\n  geom_line(size = 15, color = \"black\") +  # Adjust line size to a reasonable value\n  scale_y_continuous(limits = c(NA, 50)) + # Set the upper limit of y-axis to 50\n  labs(title = \"Mean weevils per plant 35 DPA\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  }
]