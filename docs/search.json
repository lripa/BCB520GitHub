[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Welcome to Lucas’ GitHub!",
    "section": "",
    "text": "Hi, welcome to Lucas Ripa’s GitHub.\nI’m an agricultural engineer from Chile who came to the US to pursue an MSc in entomology and made the decision to continue pursuing a PhD in entomology. I guess I like insects… My goal is to improve agricultural practices, finding ways to reduce inputs and maximize yields (lowering pests populations)."
  },
  {
    "objectID": "posts/Midterm/midterm.html",
    "href": "posts/Midterm/midterm.html",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "",
    "text": "The main goal of this midterm is to assess the University of Idaho’s performance regarding awarded grants and how it compares to other geographically close universities. The funding agencies are: The National Science Foundation, The National Institutes of Health, The Department of Energy, and The US Department of Agriculture.\nWe have been provided with several data sets from four different funding agencies. A quick overview of each funding agency is provided below:\n1.- Department of Energy (DOE)\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\ntry({\n  DOE &lt;- read_xlsx(\"DOEawards.xlsx\")\n  \n  DOE_UI &lt;- DOE %&gt;% \n    dplyr::filter(Institution == 'Regents of the University of Idaho')\n  \n  DOE_UIFiltered &lt;- DOE_UI %&gt;%\n    select(Title, Institution, PI, Status, `Program Office`, `Start Date`, `End Date`, `Amount Awarded to Date`)\n  \n  # Display the table\n  knitr::kable(head(DOE_UIFiltered))\n}, silent = TRUE)\n\n\nNew names:\n• `` -&gt; `...27`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInstitution\nPI\nStatus\nProgram Office\nStart Date\nEnd Date\nAmount Awarded to Date\n\n\n\n\nNuclear Theory at the University of Idaho\nRegents of the University of Idaho\nSammarruca, Francesca\nActive\nOffice of Nuclear Physics\n12/01/2021\n11/30/2024\n1812000\n\n\nConverting methoxy groups on lignin-derived aromatics from a toxic hurdle to a useful resource: a systems-driven approach\nRegents of the University of Idaho\nMarx, Christopher\nActive\nOffice of Biological & Environmental Research\n09/01/2021\n08/31/2024\n1404162\n\n\nIntegrative Imaging of Plant Roots during Symbiosis with Mycorrhizal Fungi\nRegents of the University of Idaho\nVasdekis, Andreas\nActive\nOffice of Biological & Environmental Research\n08/15/2021\n08/14/2024\n1519359\n\n\nNutrient and Fine Sediment Transport Driven by Perturbations in River Bed Movement\nRegents of the University of Idaho\nYager, Elowyn\nActive\nOffice of Biological & Environmental Research\n09/01/2020\n08/31/2024\n603903\n\n\n\n\n\n2.- The National Institutes of Health (NIH)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Attempt to read the Excel file and process it\ntry({\n  # Read the Excel file into a data frame\n  NIH &lt;- read_xlsx(\"NIH.xlsx\")\n  \n  # Filter and select specific columns from the NSF data frame\n  NIH_Filtered &lt;- NIH %&gt;%\n    select(contact_pi_name, award_amount, budget_start)\n  \n  # Display the table using knitr::kable\n  knitr::kable(head(NIH_Filtered))\n}, silent = TRUE)\n\n\n\n\n\ncontact_pi_name\naward_amount\nbudget_start\n\n\n\n\nMCGUIRE, MICHELLE KAY\n2354626\n2024-03-11T12:03:00Z\n\n\nWILLIAMS, JANET E.\n461621\n2024-01-15T12:01:00Z\n\n\nCHEN, YIMIN\n162320\n2024-01-15T12:01:00Z\n\n\nLANE, GINNY\n153322\n2024-01-15T12:01:00Z\n\n\nMCGUIRE, MICHELLE KAY\n300000\n2024-01-15T12:01:00Z\n\n\nMCGUIRE, MICHELLE KAY\n946131\n2024-01-15T12:01:00Z\n\n\n\n\n\n3.- Department of Agriculture (NIFA)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(knitr)\nUSDA_UI  &lt;- read.csv(\"USDAtoUI.csv\")\nknitr::kable(head(USDA_UI))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAward.Date\nGrant.Number\nProposal.Number\nGrant.Title\nState.Name\nGrantee.Name\nAward.Dollars\nProgram.Name\nProgram.Area.Name\n\n\n\n\n2010-09-30\n2010-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n7495\nN/A\nN/A\n\n\n2009-09-30\n2009-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n6813\nN/A\nN/A\n\n\n2008-09-30\n2008-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n8524\nN/A\nN/A\n\n\n2003-09-30\n2003-48604-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n1097\nN/A\nN/A\n\n\n2010-09-30\n2010-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n11997\nN/A\nN/A\n\n\n2009-09-30\n2009-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n14990\nN/A\nN/A\n\n\n\n\n\n4.- The National Science Foundation (NSF)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Attempt to read the Excel file and process it\ntry({\n  # Read the Excel file into a data frame\n  NSF &lt;- read_xlsx(\"NSFtoUI.xlsx\")\n  \n  # Filter and select specific columns from the NSF data frame\n  NSF_Filtered &lt;- NSF %&gt;%\n    select(pdPIName, startDate, expDate, estimatedTotalAmt)\n  \n  # Display the table using knitr::kable\n  knitr::kable(head(NSF_Filtered))\n}, silent = TRUE)\n\n\n\n\n\npdPIName\nstartDate\nexpDate\nestimatedTotalAmt\n\n\n\n\nDave Lien\n04/01/2024\n03/31/2026\n628415.00\n\n\nKristopher V Waynant\n04/01/2024\n03/31/2027\n456051.00\n\n\nTara Hudiburg\n03/01/2024\n08/31/2025\n1000000.00\n\n\nJulie M Amador\n12/01/2023\n11/30/2027\n1179977.00\n\n\nEsteban A Hernandez Vargas\n11/01/2023\n10/31/2025\n250000.00\n\n\nLilian Alessa\n10/01/2023\n09/30/2027\n2435509.00"
  },
  {
    "objectID": "posts/Midterm/midterm.html#preamble",
    "href": "posts/Midterm/midterm.html#preamble",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "",
    "text": "The main goal of this midterm is to assess the University of Idaho’s performance regarding awarded grants and how it compares to other geographically close universities. The funding agencies are: The National Science Foundation, The National Institutes of Health, The Department of Energy, and The US Department of Agriculture.\nWe have been provided with several data sets from four different funding agencies. A quick overview of each funding agency is provided below:\n1.- Department of Energy (DOE)\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\ntry({\n  DOE &lt;- read_xlsx(\"DOEawards.xlsx\")\n  \n  DOE_UI &lt;- DOE %&gt;% \n    dplyr::filter(Institution == 'Regents of the University of Idaho')\n  \n  DOE_UIFiltered &lt;- DOE_UI %&gt;%\n    select(Title, Institution, PI, Status, `Program Office`, `Start Date`, `End Date`, `Amount Awarded to Date`)\n  \n  # Display the table\n  knitr::kable(head(DOE_UIFiltered))\n}, silent = TRUE)\n\n\nNew names:\n• `` -&gt; `...27`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInstitution\nPI\nStatus\nProgram Office\nStart Date\nEnd Date\nAmount Awarded to Date\n\n\n\n\nNuclear Theory at the University of Idaho\nRegents of the University of Idaho\nSammarruca, Francesca\nActive\nOffice of Nuclear Physics\n12/01/2021\n11/30/2024\n1812000\n\n\nConverting methoxy groups on lignin-derived aromatics from a toxic hurdle to a useful resource: a systems-driven approach\nRegents of the University of Idaho\nMarx, Christopher\nActive\nOffice of Biological & Environmental Research\n09/01/2021\n08/31/2024\n1404162\n\n\nIntegrative Imaging of Plant Roots during Symbiosis with Mycorrhizal Fungi\nRegents of the University of Idaho\nVasdekis, Andreas\nActive\nOffice of Biological & Environmental Research\n08/15/2021\n08/14/2024\n1519359\n\n\nNutrient and Fine Sediment Transport Driven by Perturbations in River Bed Movement\nRegents of the University of Idaho\nYager, Elowyn\nActive\nOffice of Biological & Environmental Research\n09/01/2020\n08/31/2024\n603903\n\n\n\n\n\n2.- The National Institutes of Health (NIH)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Attempt to read the Excel file and process it\ntry({\n  # Read the Excel file into a data frame\n  NIH &lt;- read_xlsx(\"NIH.xlsx\")\n  \n  # Filter and select specific columns from the NSF data frame\n  NIH_Filtered &lt;- NIH %&gt;%\n    select(contact_pi_name, award_amount, budget_start)\n  \n  # Display the table using knitr::kable\n  knitr::kable(head(NIH_Filtered))\n}, silent = TRUE)\n\n\n\n\n\ncontact_pi_name\naward_amount\nbudget_start\n\n\n\n\nMCGUIRE, MICHELLE KAY\n2354626\n2024-03-11T12:03:00Z\n\n\nWILLIAMS, JANET E.\n461621\n2024-01-15T12:01:00Z\n\n\nCHEN, YIMIN\n162320\n2024-01-15T12:01:00Z\n\n\nLANE, GINNY\n153322\n2024-01-15T12:01:00Z\n\n\nMCGUIRE, MICHELLE KAY\n300000\n2024-01-15T12:01:00Z\n\n\nMCGUIRE, MICHELLE KAY\n946131\n2024-01-15T12:01:00Z\n\n\n\n\n\n3.- Department of Agriculture (NIFA)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(knitr)\nUSDA_UI  &lt;- read.csv(\"USDAtoUI.csv\")\nknitr::kable(head(USDA_UI))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAward.Date\nGrant.Number\nProposal.Number\nGrant.Title\nState.Name\nGrantee.Name\nAward.Dollars\nProgram.Name\nProgram.Area.Name\n\n\n\n\n2010-09-30\n2010-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n7495\nN/A\nN/A\n\n\n2009-09-30\n2009-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n6813\nN/A\nN/A\n\n\n2008-09-30\n2008-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n8524\nN/A\nN/A\n\n\n2003-09-30\n2003-48604-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n1097\nN/A\nN/A\n\n\n2010-09-30\n2010-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n11997\nN/A\nN/A\n\n\n2009-09-30\n2009-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n14990\nN/A\nN/A\n\n\n\n\n\n4.- The National Science Foundation (NSF)\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Attempt to read the Excel file and process it\ntry({\n  # Read the Excel file into a data frame\n  NSF &lt;- read_xlsx(\"NSFtoUI.xlsx\")\n  \n  # Filter and select specific columns from the NSF data frame\n  NSF_Filtered &lt;- NSF %&gt;%\n    select(pdPIName, startDate, expDate, estimatedTotalAmt)\n  \n  # Display the table using knitr::kable\n  knitr::kable(head(NSF_Filtered))\n}, silent = TRUE)\n\n\n\n\n\npdPIName\nstartDate\nexpDate\nestimatedTotalAmt\n\n\n\n\nDave Lien\n04/01/2024\n03/31/2026\n628415.00\n\n\nKristopher V Waynant\n04/01/2024\n03/31/2027\n456051.00\n\n\nTara Hudiburg\n03/01/2024\n08/31/2025\n1000000.00\n\n\nJulie M Amador\n12/01/2023\n11/30/2027\n1179977.00\n\n\nEsteban A Hernandez Vargas\n11/01/2023\n10/31/2025\n250000.00\n\n\nLilian Alessa\n10/01/2023\n09/30/2027\n2435509.00"
  },
  {
    "objectID": "posts/Midterm/midterm.html#data-dictionary-table",
    "href": "posts/Midterm/midterm.html#data-dictionary-table",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "Data Dictionary table",
    "text": "Data Dictionary table\nIn general all the data sets shares the same variables with different names. The most commonly used ones are summarized in the table below:\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(knitr)\ndatatable  &lt;- read_xlsx(\"DataDictionary.xlsx\")\nknitr::kable(head(datatable))\n\n\n\n\n\nAttribute\nDescription\nType\n\n\n\n\nPI\nPrincipal Investigator\nCharacter\n\n\nInstitution\nUniversity/instiution name\nCharacter\n\n\nStart date\nDate where the award started\nDate\n\n\nEnd date\nDate where the award ends\nDate\n\n\nCode\nInternal code of the award\nNumeric\n\n\nAmount\nAmount of money awarded\nNumeric"
  },
  {
    "objectID": "posts/Midterm/midterm.html#question-1",
    "href": "posts/Midterm/midterm.html#question-1",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "QUESTION 1:",
    "text": "QUESTION 1:\nProvide a visualization that shows our active awards from each sponsor. I need to see their start date and end date, the amount of the award, and the name of the Principal Investigator. I’m really interested in seeing how far into the future our current portfolio will exist. Are there a bunch of awards about to expire? Are there a bunch that just got funded and will be active for a while? Does this vary across sponsors?\nLets take a look at historical data:\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nfunding_data &lt;- read_xlsx(\"UIawards3.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Count the unique PIs per agency\npi_count_per_agency &lt;- funding_data %&gt;%\n  group_by(Agency) %&gt;%\n  summarise(PI_Count = n_distinct(PI))\n\n# Filter for the specific agencies if the dataset contains more agencies\npi_count_per_agency &lt;- pi_count_per_agency %&gt;%\n  filter(Agency %in% c(\"NSF\", \"NIH\", \"DOE\"))\n\n# Create the bar chart\nggplot(pi_count_per_agency, aes(x = Agency, y = PI_Count, fill = Agency)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Total number of PIs Per Funding Agency in UofI since 1998\",\n       x = \"Agency\",\n       y = \"Number of PIs\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set3\")\n\n\n\n\n\nCode\ntotal_amount_per_agency &lt;- funding_data %&gt;%\n  group_by(Agency) %&gt;%\n  summarise(TotalAmount = sum(Amount, na.rm = TRUE) / 1e6) # Convert to millions\n\n# Filter for the specific agencies if the dataset contains more agencies\ntotal_amount_per_agency &lt;- total_amount_per_agency %&gt;%\n  filter(Agency %in% c(\"NSF\", \"NIH\", \"DOE\"))\n\n# Create the bar chart for total funding amount per agency in USD millions\nggplot(total_amount_per_agency, aes(x = Agency, y = TotalAmount, fill = Agency)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Total Funding Amount Per Funding Agency in UofI since 1998\",\n       x = \"Agency\",\n       y = \"Total Funding Amount (USD Millions)\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set3\")\n\n\n\n\n\nSince 1998, NSF is the agency with the most PIs in UofI recent history. Looking at the total funding amount per agency, NIH and NSF are pretty close, this tell us that there are a group of PIs that gets constantly funded with large amounts in NIH. DOE is the area where UofI can grow the most, and more effort should be invested into.\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# Read data from an Excel file\nUSDA10 &lt;- read_xlsx(\"USDA10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Convert start to Date objects\nUSDA10$start &lt;- as.Date(USDA10$start, format = \"%m/%d/%Y\")\n\n# Handle end date: Assuming you have only the year, create a Date object for December 31st of that year\nUSDA10$end &lt;- as.Date(paste0(USDA10$end, \"-12-31\"), format = \"%Y-%m-%d\")\n\n# Create the Gantt chart\nggplot(USDA10, aes(y = Agency, x = start, xend = end, yend = Agency)) +\n  geom_segment(size = 10, color = \"green\") + # Adjust the size as needed\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", limits = c(as.Date(\"2021-01-01\"), as.Date(\"2029-01-01\"))) +\n  labs(title = \"10 years of active USDA funding\",\n       x = \"Timeline\",\n       y = \"Agency\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 166 rows containing missing values (`geom_segment()`).\n\n\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Read data from an Excel file\nDOE10 &lt;- read_xlsx(\"DOE10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Convert start and end to Date objects\n# Assuming your Excel file has columns named 'start' and 'end'\nDOE10$start &lt;- as.Date(DOE10$start, format = \"%m/%d/%Y\")\nDOE10$end &lt;- as.Date(DOE10$end, format = \"%m/%d/%Y\")\n\n# Create the Gantt chart\nggplot(DOE10, aes(y = Agency, x = start, xend = end, yend = Agency)) +\n  geom_segment(size = 20, color = \"black\") + # Use linewidth instead of size\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", limits = c(as.Date(\"2021-01-01\"), as.Date(\"2029-01-01\"))) +\n  labs(title = \"10 years of active DOE funding\",\n       x = \"Timeline\",\n       y = \"Agency\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning: Removed 1 rows containing missing values (`geom_segment()`).\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(RColorBrewer)\n\n\n# Aggregate data to get the total amount per PI and filter out amounts smaller than 200000\ntotal_amount_per_PI &lt;- DOE10 %&gt;%\n  group_by(PI) %&gt;%\n  summarise(TotalAmount = sum(Amount, na.rm = TRUE)) %&gt;%\n  filter(TotalAmount &gt;= 200000) %&gt;%  # Filter step added here\n  arrange(desc(TotalAmount))\n\nggplot(total_amount_per_PI, aes(x = PI, y = TotalAmount / 1e6)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"DOE Total Funding per PI in the Last 10 Years\",\n       y = \"Total Funding Amount (USD Millions)\",\n       x = \"Principal Investigator\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate X-axis labels for readability\n\n\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Read data from an Excel file\nNSF10 &lt;- read_xlsx(\"NSF10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Convert start and end to Date objects\n# Assuming your Excel file has columns named 'start' and 'end'\nNSF10$start &lt;- as.Date(NSF10$start, format = \"%m/%d/%Y\")\nNSF10$end &lt;- as.Date(NSF10$end, format = \"%m/%d/%Y\")\n\n# Create the Gantt chart\nggplot(NSF10, aes(y = Agency, x = start, xend = end, yend = Agency)) +\n  geom_segment(size = 20, color = \"red\") + # Use linewidth instead of size\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", limits = c(as.Date(\"2021-01-01\"), as.Date(\"2029-01-01\"))) +\n  labs(title = \"10 years of active NSF funding\",\n       x = \"Timeline\",\n       y = \"Agency\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning: Removed 81 rows containing missing values (`geom_segment()`).\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(RColorBrewer)\n\nNSF10 &lt;- read_xlsx(\"NSF10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Aggregate data to get the total amount per PI and filter out amounts smaller than 200000\ntotal_amount_per_PI &lt;- NSF10 %&gt;%\n  group_by(PI) %&gt;%\n  summarise(TotalAmount = sum(Amount, na.rm = TRUE)) %&gt;%\n  filter(TotalAmount &gt;= 200000) %&gt;%  # Filter step added here\n  arrange(desc(TotalAmount))\n\nggplot(total_amount_per_PI, aes(x = PI, y = TotalAmount / 1e6)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"NSF Total Funding per PI in the Last 10 Years\",\n       y = \"Total Funding Amount (USD Millions)\",\n       x = \"Principal Investigator\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate X-axis labels for readability\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(lubridate)\n\ndf &lt;- read_xlsx(\"UIawards.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Assuming your dataset is named df\n# Clean 'Agency' data (remove leading/trailing spaces, check for case sensitivity)\ndf$Agency &lt;- as.character(trimws(df$Agency))\n\n# Convert 'start' and 'end' columns to Date format\ndf$start &lt;- as.Date(df$start, format = \"%Y-%m-%d\")\ndf$end &lt;- as.Date(df$end, format = \"%Y-%m-%d\")\n\n# Create a timeline that spans 10 years back and 10 years forward from today\ntimeline_start &lt;- Sys.Date() - years(10)\ntimeline_end &lt;- Sys.Date() + years(10)\n\n# Plotting\nggplot(df, aes(y = factor(Agency, levels = unique(Agency)), x = start, xend = end, yend = factor(Agency, levels = unique(Agency)))) +\n  geom_segment(size = 20, color = \"blue\") +  # Adjust size and color as needed\n  scale_x_date(limits = c(timeline_start, timeline_end), date_breaks = \"1 year\", date_labels = \"%Y\") +\n  labs(title = \"10 years of Active NIH  Timeline\",\n       x = \"Year\",\n       y = \"Agency\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 7),\n        panel.grid.major.x = element_line(color = \"grey80\"),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank())\n\n\nWarning: Removed 74 rows containing missing values (`geom_segment()`).\n\n\n\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(RColorBrewer)\n\nNIH10 &lt;- read_xlsx(\"NIH10UI.xlsx\")\n\n\nNew names:\n• `` -&gt; `...4`\n• `` -&gt; `...6`\n\n\nCode\n# Aggregate data to get the total amount per PI and filter out amounts smaller than 200000\ntotal_amount_per_PI &lt;- NIH10 %&gt;%\n  group_by(PI) %&gt;%\n  summarise(TotalAmount = sum(Amount, na.rm = TRUE)) %&gt;%\n  filter(TotalAmount &gt;= 200000) %&gt;%  # Filter step added here\n  arrange(desc(TotalAmount))\n\nggplot(total_amount_per_PI, aes(x = PI, y = TotalAmount / 1e6)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"NIH Total Funding per PI in the Last 10 Years\",\n       y = \"Total Funding Amount (USD Millions)\",\n       x = \"Principal Investigator\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate X-axis labels for readability\n\n\n\n\n\nAccording to the plotted data, NSF and NIH appear to have secured grants into the furthest future, (2028-2029). DOE has the largest grow potential, since just 4 PIs have grants."
  },
  {
    "objectID": "posts/Midterm/midterm.html#question-3",
    "href": "posts/Midterm/midterm.html#question-3",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "QUESTION 3:",
    "text": "QUESTION 3:\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nBU &lt;- read_xlsx(\"NIH.xlsx\")\n\n# Use 'BU' instead of 'df' for operations\nselected_universities &lt;- BU %&gt;%\n  filter(organization.org_name %in% c(\"BOISE STATE UNIVERSITY\", \"UNIVERSITY OF IDAHO\")) %&gt;%\n  group_by(organization.org_name) %&gt;%\n  summarise(total_award_amount = sum(award_amount, na.rm = TRUE))\n\n# Create the bar chart\nggplot(selected_universities, aes(x = organization.org_name, y = total_award_amount, fill = organization.org_name)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Total Award Amount by University NIH\",\n       x = \"University\",\n       y = \"Total Award Amount NIH\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"BOISE STATE UNIVERSITY\" = \"blue\", \"UNIVERSITY OF IDAHO\" = \"gold\"))\n\n\n\n\n\nLets focus on USDA grants, since I’m in CALS, it makes sense to take a deeper look into USDA.\n\n\nCode\n# Load necessary libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# Read the CSV file\ndata &lt;- read_csv(\"USDAallU.csv\")\n\n\nRows: 2314 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Award Date, Grant Number, Proposal Number, Grant Title, State Name,...\ndbl (1): Award Dollars\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# Convert 'Award Date' to Date object using correct format and filter data from 2014 to 2024\ndata &lt;- data %&gt;%\n  mutate(AwardDate = mdy(`Award Date`)) %&gt;%\n  filter(AwardDate &gt;= as.Date(\"2014-01-01\") & AwardDate &lt;= as.Date(\"2024-12-31\"))\n\n# Aggregate data to get the total Award Dollars for each Grantee Name\ntotal_award_per_grantee &lt;- data %&gt;%\n  group_by(`Grantee Name`) %&gt;%\n  summarise(TotalAwardDollars = sum(`Award Dollars`, na.rm = TRUE)) %&gt;%\n  arrange(desc(TotalAwardDollars)) # Optional: arrange in descending order of total award dollars\n# Assuming total_award_per_grantee is already created from previous steps\n\n# Convert Grantee Name to a factor (if not already)\ntotal_award_per_grantee$`Grantee Name` &lt;- factor(total_award_per_grantee$`Grantee Name`)\n\n# Assuming custom_colors is correctly mapped to your Grantee Names\ncustom_colors &lt;- c(\"Boise State University\" = \"blue\", \n                   \"University of Idaho\" = \"gold\", \n                   \"Washington State University\" = \"red\", \n                   \"University of Montana\" = \"tan\")\n\n\nggplot(total_award_per_grantee, aes(x = reorder(`Grantee Name`, TotalAwardDollars), y = TotalAwardDollars / 1e6, fill = `Grantee Name`)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"Boise State University\" = \"blue\", \n                   \"University of Idaho\" = \"gold\", \n                   \"Washington State University\" = \"red\", \n                   \"University of Montana\" = \"tan\")) +\n  labs(title = \"USDA Total Award Dollars per University (2014-2024)\",\n       x = \"Univeristy\",\n       y = \"Total Award Dollars (Millions USD)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))  # For better readability of Grantee Names\n\n\n\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# Read the data\ndata &lt;- read_csv(\"USDAallU.csv\")\n\n\nRows: 2314 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Award Date, Grant Number, Proposal Number, Grant Title, State Name,...\ndbl (1): Award Dollars\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# Prepare the data by grouping and summarising\ngrants_per_grantee &lt;- data %&gt;%\n  group_by(`Grantee Name`) %&gt;%\n  summarise(NumberOfGrants = n()) %&gt;%\n  arrange(desc(NumberOfGrants))  # Optional: arrange in descending order of number of grants\n\n# Define custom colors for specific Grantee Names\ncustom_colors &lt;- c(\"Boise State University\" = \"blue\", \n                   \"University of Idaho\" = \"gold\", \n                   \"Washington State University\" = \"red\", \n                   \"University of Montana\" = \"tan\")\n\n# Create the bar graph with custom colors\nggplot(grants_per_grantee, aes(x = reorder(`Grantee Name`, NumberOfGrants), y = NumberOfGrants, fill = `Grantee Name`)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = custom_colors) +  # Apply custom colors\n  labs(title = \"Number of Grants per Grantee\",\n       x = \"Grantee Name\",\n       y = \"Number of Grants\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))  # Rotate X-axis labels for better readability"
  },
  {
    "objectID": "posts/Midterm/midterm.html#conclusions",
    "href": "posts/Midterm/midterm.html#conclusions",
    "title": "“BCB 520 - Midterm Portfolio Post”",
    "section": "Conclusions",
    "text": "Conclusions\nLet me start by saying that the 80/20 rule is completely accurate. I probably spent more than 80% of the time cleaning, merging, and generally preparing the appropriate data sets to produce these few data visualizations. There’s no convention among funding agencies on how they report their data; this would make things way easier for universities and institutions to have an idea of how they are doing in comparison to the rest.\nDOE shows the largest growing potential, with just 4 PIs; there’s a big opportunity to grow.\nUofI has a solid funding history with NIH with a few anchor PIs that got large total amounts.\nIn general, UofI is doing well, especially with USDA. Considering its size (around 12,000 students), UofI is comparable to Montana State (10,000 students), and the data shows it; numbers are similar for USDA. WSU (23,000 students) is significantly larger and it makes sense that it got more USDA projects. Boise State (23,000 students) is not an agricultural sciences-based university, but it is as large as WSU, so if they were to get into agricultural sciences, they would certainly be a threat to UofI’s USDA funding.\nWhat I learned is that these types of analyses are way more complicated than they look. Choosing the right variables and presenting the data in a meaningful way is critical to arriving at the right conclusions. Also, since there’s a significant amount of data wrangling involved, the chances of making a mistake can’t be overlooked, so a quality assessment is mandatory to double-check for any possible mistakes."
  },
  {
    "objectID": "posts/Final/final.html",
    "href": "posts/Final/final.html",
    "title": "Final",
    "section": "",
    "text": "Preamble\nSince 2021, I have served on at the Institute for Health in the Human Ecosystem (IHHE) as advisory committee student representative. During this time, I have witnessed the Biology of Vector-borne Diseases (BVBD) course growing popularity and a significant increase in the number of applicants over the years. Thus, a logical idea emerged (for which I must credit Dr. Barrie Robison) to visualize these data on a world map\n\n\n\nInstitute for Health in the Human Ecosystem (IHHE) logo.\n\n\nHere’s a description of the Biology of Vector-borne Diseases course that’s hosted at the University of Idaho every year, taken from the IHHE webpage:\n“The Institute for Health in the Human Ecosystem hosts the annual Biology of Vector-borne Diseases six-day course. This course provides accessible, condensed training and”knowledge networking” for advanced graduate students, postdoctoral fellows, faculty and professionals to ensure competency in basic biology, current trends and developments, and practical knowledge for U.S. and global vector-borne diseases of plants, animals and humans. We seek to train the next generation of scientists and help working professionals to more effectively address current and emerging threats with holistic approaches and a strong network of collaborators and mentors.”\nHere’s a link to the IHHE website:\nhttps://www.uidaho.edu/research/entities/ihhe/education/vector-borne-diseases\nSo, as part of the organizing advisory committee, we have been considering how to examine the evolution and popularity of the course applicants over the last six years. A suitable visualization would be a world map displaying the home countries of the applicants, year by year.\n\n\nData\nThe data set contains two variables. Year and Country. Year is the date when the course was offered, and Country is where the applicant is applying from, which in the end is used as spatial data.\n\n\nCode\nlibrary(readxl) \nparticipants &lt;- readxl::read_excel(\"BVBD Applicants Merged.xlsx\")\nhead(participants)\n\n\n# A tibble: 6 × 2\n   Year Country                 \n  &lt;dbl&gt; &lt;chr&gt;                   \n1  2018 United States of America\n2  2018 Nigeria                 \n3  2018 United States of America\n4  2018 United States of America\n5  2018 United States of America\n6  2018 United States of America\n\n\n\n\nVisualizations\nFirst, let’s start with simple maps. As we have simple data, without geometry/coordinates, it was necessary to convert Country data names into coordinates in order to plot them into the map.\n\n\nCode\nlibrary(rnaturalearth)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(readxl) \nparticipants &lt;- readxl::read_excel(\"BVBD Applicants Merged.xlsx\")\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nworld$centroid_lon &lt;- st_coordinates(st_centroid(world$geometry))[, 1]\nworld$centroid_lat &lt;- st_coordinates(st_centroid(world$geometry))[, 2]\nparticipants_with_centroids &lt;- participants %&gt;%\n  left_join(world %&gt;% select(name, centroid_lon, centroid_lat), by = c(\"Country\" = \"name\"))\nggplot(data = participants_with_centroids) +\n  borders(\"world\", colour = \"gray\", fill = \"lightgray\") + # Draw the base map\n  geom_point(aes(x = centroid_lon, y = centroid_lat, color = as.factor(Year), shape = as.factor(Year)), size = 2) + # Plot points with varying colors and shapes per Year\n  scale_color_viridis_d(name = \"Year\") + # Use a nice color scale for colors\n  scale_shape_manual(name = \"Year\", values = c(16, 17, 18, 19, 15, 8)) + # Manually set shapes, adjust values as needed based on the number of years\n  theme_minimal() +\n  labs(title = \"Applicants by Country and Year\", x = \"Longitude\", y = \"Latitude\", color = \"Year\", shape = \"Year\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 1. Distribution of applicants by country and year.\n\n\nCode\n# Assuming 'participants' has a 'Country' column\n# Count the number of applicants per country\napplicants_summary &lt;- participants %&gt;%\n  group_by(Country) %&gt;%\n  summarise(Applicants = n())\n\n# Join with world data to include geometry\nworld_with_applicants &lt;- world %&gt;%\n  left_join(applicants_summary, by = c(\"name\" = \"Country\"))\n\n# Plot with a gradient fill based on the number of applicants\nggplot(data = world_with_applicants) +\n  geom_sf(aes(fill = Applicants), color = \"white\") +\n  scale_fill_viridis_c(name = \"Number of Applicants\", na.value = \"lightgrey\", \n                       limits = c(1, 150), oob = scales::squish) +  # Set the range from 1 to 150\n  labs(title = \"Global Distribution of Applicants\") +\n  theme_minimal()\n\n\n\n\n\nFigure 2. Global distribution of applicants.\nOk, let’s try an interactive map, using the total number of applicants for the six years that the course has been offered. This map let us zoom in, see the name of each country and number of applicants per country.\n\n\nCode\nlibrary(dplyr)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(leaflet)\nlibrary(viridis)\nlibrary(readxl)\n\nparticipants &lt;- readxl::read_excel(\"BVBD Applicants Merged.xlsx\")\n\n# Count the number of applicants per country\napplicants_summary &lt;- participants %&gt;%\n  group_by(Country) %&gt;%\n  summarise(Applicants = n()) %&gt;%\n  ungroup()\n\n# Get world countries' spatial data\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# Merge applicants data with spatial data\nworld_with_applicants &lt;- world %&gt;%\n  left_join(applicants_summary, by = c(\"name\" = \"Country\"))\n\n# Assuming the majority of your data points are in the lower range (e.g., 1-10),\n# and you want to ensure these differences are visible, adjust the domain accordingly\n# Here, we manually define the domain to ensure the lower counts are differentiated\nmin_applicants &lt;- min(world_with_applicants$Applicants, na.rm = TRUE)\nmax_applicants &lt;- max(world_with_applicants$Applicants, na.rm = TRUE)\n\n# Define a color palette function based on the number of applicants\nqpal &lt;- colorNumeric(palette = \"viridis\", domain = c(min_applicants, max_applicants), na.color = \"lightgrey\")\n\n# Create the leaflet map with enhanced highlight functionality\nleaflet(world_with_applicants) %&gt;%\n  addProviderTiles(providers$CartoDB.Positron) %&gt;%\n  addPolygons(fillColor = ~qpal(Applicants),\n              color = \"#2b2b2b\",  # Default outline color\n              fillOpacity = 0.7,\n              weight = 0.5,  # Default outline weight\n              popup = ~paste(name, \"&lt;br&gt;\", \"Applicants: \", Applicants),\n              highlightOptions = highlightOptions(weight = 5,  # Thicker outline when highlighted\n                                                  color = \"#FFFF00\",  # Bright yellow outline when highlighted\n                                                  fillOpacity = 0.7,\n                                                  bringToFront = TRUE)) %&gt;%\n  addLegend(pal = qpal, values = ~Applicants,\n            title = \"Number of Applicants\",\n            position = \"bottomright\") %&gt;%\n  setView(lat = 0, lng = 0, zoom = 2)\n\n\n\n\n\n\nFigure 3. Interactive map of global distribution of applicants, with information per country.\nLet’s dive even further. Let’s try a 3D world map.\n\n\nCode\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(countrycode)\n\n# Aggregating the number of applicants per country\napplicants_summary &lt;- participants %&gt;%\n  group_by(Country) %&gt;%\n  summarise(Applicants = n()) %&gt;%\n  ungroup()\n\n# Adding ISO country codes to 'applicants_summary' for Plotly\napplicants_summary$CODE &lt;- countrycode(applicants_summary$Country, \"country.name\", \"iso3c\")\n\n# Handling missing or incorrect country names\napplicants_summary &lt;- na.omit(applicants_summary)\n\n# Specify map projection and options\ng &lt;- list(\n     showframe = FALSE,\n     showcoastlines = FALSE,\n     projection = list(type = 'orthographic'),\n     resolution = '100',\n     showcountries = TRUE,\n     countrycolor = '#d1d1d1',\n     showocean = TRUE,\n     oceancolor = '#c9d2e0',\n     showlakes = TRUE,\n     lakecolor = '#99c0db',\n     showrivers = TRUE,\n     rivercolor = '#99c0db')\n\n# Plotting with simplified trace\np &lt;- plot_geo(applicants_summary, locations = ~CODE, text = ~paste(Country, '&lt;br&gt;Applicants: ', Applicants),\n              marker = list(size = ~sqrt(Applicants) * 10, color = ~Applicants, colorscale = 'Reds', line = list(color = \"#d1d1d1\", width = 0.5))) %&gt;%\n     colorbar(title = 'Number of Applicants') %&gt;%\n     layout(title = 'Number of Applicants Per Country', geo = g)\n\np\n\n\n\n\n\n\nFigure 4. Interactive map (3D) of global distribution of applicants, per country.\n\nConclusions or Summary\nThe type of visualization certainly depends on the purpose it is going to serve. For example, Figures 1 and 2 are best suited for a publication or poster, where interactivity is not possible. For a webpage, Figures 3 and 4 are more appealing and draw more attention from the viewer, enabling the possibility to examine specific countries with precise data presented upon request."
  },
  {
    "objectID": "posts/Winter Sports/index.html",
    "href": "posts/Winter Sports/index.html",
    "title": "Hockey DataViz (A5)",
    "section": "",
    "text": "Demonstrate that you can manipulate tabular data to facilitate different visualization tasks. The minimum skills are FILTERING, SELECTING, and SUMMARIZING, all while GROUPING these operations as dictated by your data.\nDemonstrate that you can use tabular data to explore, analyze, and choose the most appropriate visualization idioms given a specific motivating question.\nDemonstrate that you can Find, Access, and Integrate additional data in order to fully address the motivating question."
  },
  {
    "objectID": "posts/Winter Sports/index.html#learning-objectives",
    "href": "posts/Winter Sports/index.html#learning-objectives",
    "title": "Hockey DataViz (A5)",
    "section": "",
    "text": "Demonstrate that you can manipulate tabular data to facilitate different visualization tasks. The minimum skills are FILTERING, SELECTING, and SUMMARIZING, all while GROUPING these operations as dictated by your data.\nDemonstrate that you can use tabular data to explore, analyze, and choose the most appropriate visualization idioms given a specific motivating question.\nDemonstrate that you can Find, Access, and Integrate additional data in order to fully address the motivating question."
  },
  {
    "objectID": "posts/Winter Sports/index.html#scenario",
    "href": "posts/Winter Sports/index.html#scenario",
    "title": "Hockey DataViz (A5)",
    "section": "SCENARIO",
    "text": "SCENARIO\nFor the purposes of this exercise, let’s set the 2024 NHL draft order using the Tankathon Simulator. The NHL uses a lottery system in which the teams lowest in the standings have the highest odds of getting the first overall pick. This year the Canucks are at the top of the league, and positioned to have the 31st overall pick. According to the simulator, Calgary will pick at number 2 (which is very valuable!), and the Canuck’s pick at 31.\nHere is the question:\nWas the trade worth it? This trade has a high likelihood of becoming what we call a rental. Elias Lindholm is on an expiring contract, meaning Vancouver is guaranteed to hold his contract only through the end of the season. They might be able to extend him, but that depends on the salary cap.\nMeanwhile, Calgary can draft a player at position 31, who may or may not turn out to be of equal or greater value than Lindholm.\nWas the trade worth it? Did Vancouver or Calgary “win” the trade?\nCan we make some visualizations that help us answer this question?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#the-data",
    "href": "posts/Winter Sports/index.html#the-data",
    "title": "Hockey DataViz (A5)",
    "section": "THE DATA",
    "text": "THE DATA\nHow can we evaluate whether trading a first round pick for a rental player is a good idea? One approach is to look at the historical performance of players from various draft positions.\n\nCodelibrary(tidyverse)\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nCodelibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readxl)\n\n\n\nCodeNHLDraft&lt;-read.csv(\"NHLDraft.csv\")\nNHLDictionary&lt;-read_excel(\"NHLDictionary.xlsx\")\nNHLStats&lt;-read.csv(\"NHLdraftstats.csv\")\nhead(NHLDraft)\n\n  X draftyear      name round overall pickinRound height weight position\n1 1      2001 Drew Fata     3      86          23     73    209  Defense\n2 2      2001 Drew Fata     3      86          23     73    209  Defense\n3 3      2001 Drew Fata     3      86          23     73    209  Defense\n4 4      2001 Drew Fata     3      86          23     73    209  Defense\n5 5      2001 Drew Fata     3      86          23     73    209  Defense\n6 6      2001 Drew Fata     3      86          23     73    209  Defense\n  playerId postdraft NHLgames\n1  8469535         0        0\n2  8469535         1        0\n3  8469535         2        0\n4  8469535         4        0\n5  8469535         5        3\n6  8469535        10        0\n\nCodeknitr::kable(NHLDictionary)\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\ndraftyear\nOrdinal\nCalendar year in which the player was drafted into the NHL.\n\n\nname\nItem\nFull name of the player.\n\n\nround\nOrdinal\nRound in which the player was drafted (1 to 7).\n\n\noverall\nOrdinal\nOverall draft position of the player (1 to 224)\n\n\npickinRound\nOrdinal\nPosition in which the player was drafted in their round (1 to 32).\n\n\nheight\nQuantitative\nPlayer height in inches.\n\n\nweight\nQuantitative\nPlayer weight in pounds.\n\n\nposition\nCategorical\nPlayer position (Forward, Defense, Goaltender)\n\n\nplayerId\nItem\nUnique ID (key) assigned to each player.\n\n\npostdraft\nOrdinal\nNumber of seasons since being drafted (0 to 20).\n\n\nNHLgames\nQuantitative\nNumber of games played in the NHL in that particular season (regular season is 82 games, playoffs are up to 28 more).\n\n\n\n\n\nIn this case, we have a dataframe with all the drafted players from 2000-2018, their position, their draft year and position, and then rows for each season since being drafted (postdraft). The key variable here is NHLgames, which tells us how many games they played in the NHL each season since being drafted. Whether drafted players even make the NHL, and how many games they play, might be a good proxy to understand the value of a draft pick we just traded away."
  },
  {
    "objectID": "posts/Winter Sports/index.html#simple-scatterplot",
    "href": "posts/Winter Sports/index.html#simple-scatterplot",
    "title": "Hockey DataViz (A5)",
    "section": "SIMPLE SCATTERPLOT",
    "text": "SIMPLE SCATTERPLOT\nOne thing to realize about professional hockey is that it is pretty rare for a player to play in the NHL right after being drafted. Players get drafted when they are 18 years old, and they usually play in the juniors, minor leagues, or the NCAA for a bit to further develop.\nLet’s use a scatterplot to visualize this phenomenon with the most recent draft classes.\n\nCodedraft2022&lt;-NHLDraft%&gt;%\n  filter(draftyear==2022 & postdraft==0)\n\n\n\n\nggplot(draft2022, aes(x=round, y=NHLgames))+\n  geom_point()\n\n\n\n\nAs you can see, the players drafted in June of 2022 didn’t play much last season. There are few things wrong with this visualization, however:\n\n\nOverplotting. All those points on the y=0 line represent about 32 players each. Can you think of a way that adding extra channels might help? Violin plots could work or jitter plots (see examples below). Also, colors will aid separate rounds.\n\n\n\nCodelibrary(ggplot2)\n\nggplot(draft2022, aes(x=factor(round), y=NHLgames, fill=factor(round))) +\n  geom_violin(trim=FALSE) +\n  labs(title = \"NHL Games by Draft Round\",\n       x = \"Draft Round\",\n       y = \"NHL Games\") +\n  theme_light() +\n  scale_fill_brewer(palette=\"Pastel1\") + \n  theme(axis.text.x = element_text(angle=45, hjust=1))\n\n\n\nCodelibrary(ggplot2)\n\nggplot(draft2022, aes(x=factor(round), y=NHLgames, color=factor(round))) +\n  geom_jitter(width = 0.2, height = 0, alpha=1) +\n  labs(title = \"NHL Games by Draft Round (Jitter Plot)\",\n       x = \"Draft Round\",\n       y = \"NHL Games\") +\n  theme_light() +\n  scale_color_brewer(palette=\"Set3\") + \n  theme(axis.text.x = element_text(angle=0, hjust=1)) \n\n\n\n\n\n\nLabelling. Can we create a solid figure caption and better axis labels for this figure? In your caption, please specify the task(s) the visualizaiton is intended to facilitate, as well as the marks, channels, and key-value pairs used. Y axis label: Number of NHL games played, X: Draft Round, channels color and shape.\n\nCodelibrary(ggplot2)\n\nggplot(draft2022, aes(x=factor(round), y=NHLgames, color=factor(round), shape=factor(round))) +\n  geom_jitter(width = 0.2, height = 0, alpha=1) +\n  labs(title = \"NHL Games by Draft Round (Jitter Plot)\",\n       x = \"Draft Round Number\",\n       y = \"Number of NHL games played\") +\n  theme_light() +\n  scale_color_brewer(palette=\"Set3\") +\n  scale_shape_manual(values=c(1:30)) + \n  theme(axis.text.x = element_text(angle=0, hjust=1))\n\n\n\n\n\nKey-Value pairs: Looks like we are using “round” as a continuous variable. Can we change this to an ordered factor?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#expanded-scatterplot",
    "href": "posts/Winter Sports/index.html#expanded-scatterplot",
    "title": "Hockey DataViz (A5)",
    "section": "EXPANDED SCATTERPLOT",
    "text": "EXPANDED SCATTERPLOT\nThe data from the most recent drafts aren’t really helpful for our question. Let’s go back in time and use a draft year that has had some time to develop and reach their potential. How about 2018?\n\nCodedraft2018&lt;-NHLDraft%&gt;%\n  filter(draftyear==2018 & postdraft&lt;6) \n\n# wondering why I've filtered postdraft to be less than 6?  Try removing that filter to see what happens.\n\nggplot(draft2018, aes(x=round, y=NHLgames))+\n  geom_point()\n\n\n\nCodelibrary(ggplot2)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nHmmm… in addition to the problem of overplotting, we’ve got an additional issue here. We actually have two keys and one attribute. The attribute is NHLgames, and the keys are round and postdraft, but we are only using round.\nPostdraft indicates the number of seasons after being drafted. We have several choices here. We can make a visualization that uses both keys, or we can somehow summarize the data for one of the keys.\nFor example, let’s say we just wanted to know the TOTAL number of NHL games played since being drafted.\n\nCodedrafttot2018&lt;- draft2018%&gt;%\n  group_by(playerId, round, overall, position, name)%&gt;%\n  summarise(totgames=sum(NHLgames))\n\n`summarise()` has grouped output by 'playerId', 'round', 'overall', 'position'.\nYou can override using the `.groups` argument.\n\nCodeggplot(drafttot2018, aes(x=round, y=totgames))+\n  geom_point()\n\n\n\n\nLook closely at the two graphs above. How are they different?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#stop-and-reflect",
    "href": "posts/Winter Sports/index.html#stop-and-reflect",
    "title": "Hockey DataViz (A5)",
    "section": "STOP AND REFLECT",
    "text": "STOP AND REFLECT\nI’ve been a bit sneaky up to this point. You’ve probably been focusing primarily on my (crappy) visualizations. That’s fine, but let’s think about the manipulations to the TABULAR DATA I’ve had to perform.\nI’m using the Tidyverse to do these manipulations. I set up the original data frame to conform to the tidy data principles (every column is a variable, every row is an observation), which is pretty much the base form of how we’ve discussed Tabular Data in class.\nI’ve snuck in some functions that have allowed me to FILTER, GROUP, and SUMMARIZE the data, often creating new dataframes as I do so. Hey, look! A handy cheatsheet for data transformation using the tidyverse!\nThese functions come from the dplyr package that gets installed as part of the tidyverse. The basic categories of actions are:\n\nmutate() adds new variables that are functions of existing variables\nselect() picks variables based on their names.\nfilter() picks cases based on their values.\nsummarise() reduces multiple values down to a single summary.\narrange() changes the ordering of the rows.\n\nAll of these work with group_by() so you can perform whichever operation on the groups that might be present in your data set.\nLet’s get back to improving our understanding of the relative value of NHL draft picks. The figure above considers a single draft class (2018), and shows the total number of NHL games all the players have accumulated, separating each draft round on an ordinal x axis.\nFine, I guess, but we still have to deal with overplotting, and think about whether a scatterplot really helps us accomplish our task. For this figure do the following:\n\n\nOverplotting. All those points on the y=0 line represent about 32 players each. Can you you think of a way that adding extra channels might help?\n\nLabelling. Can we create a solid figure caption and better axis labels for this figure? In your caption, please specify the task(s) the visualizaiton is intended to facilitate, as well as the marks, channels, and key-value pairs used.\n\nKey-Value pairs: Looks like we are using “round” as a continuous variable. Can we change this to an ordered factor?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#scatterplot-with-overall-draft-position",
    "href": "posts/Winter Sports/index.html#scatterplot-with-overall-draft-position",
    "title": "Hockey DataViz (A5)",
    "section": "SCATTERPLOT WITH OVERALL DRAFT POSITION",
    "text": "SCATTERPLOT WITH OVERALL DRAFT POSITION\nThis approach might yield a better match with the scatterplot idiom. What if we ignore draft round, and use the player’s overall draft position instead? It also might help us focus on our motivating question! What is the potential value of pick 31, and how does Elias Lindholm compare to that value?\n\nCodeggplot(drafttot2018, aes(x=overall, y=totgames))+\n  geom_point()\n\n\n\n\nFor this figure, address the following:\n\nWe are trying to address the notion of trading pick 31. How might you facilitate the task of evaluating picks in that range?\nCreate a caption and better axis labels for this figure.\nWhat if we wanted to use more than just the 2018 draft class?"
  },
  {
    "objectID": "posts/Winter Sports/index.html#scatterplot-summary",
    "href": "posts/Winter Sports/index.html#scatterplot-summary",
    "title": "Hockey DataViz (A5)",
    "section": "SCATTERPLOT SUMMARY",
    "text": "SCATTERPLOT SUMMARY\nWe seem to be running into an issue in terms of overplotting. Scatterplots are great, but they work best for two quantitative attributes, and we have a situation with one or two keys and one quantitative attribute. The thing is, scatterplots can be very useful when part of our workflow involves modeling the data in some way. We’ll cover this kind of thing in future assignments, but just a bit of foreshadowing here:\n\nCodeggplot(drafttot2018, aes(x=round, y=totgames))+\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nAdding the smoothed line doesn’t eliminate the overplotting problem, but it does indicate that it exists. We’ll cover other potential solutions (such as box plots and violin plots) to this issue later in the course, when we get to the notions of faceting and data reduction.\nWhy not include all the data? A scatter plot with that many players (4775) isn’t going to be great. But we could plot some sort of polynomial model to get a sense of the relationship between draft position and NHL games. We’ll filter to the first 8 years of their career."
  },
  {
    "objectID": "posts/Winter Sports/index.html#conclusive-figure",
    "href": "posts/Winter Sports/index.html#conclusive-figure",
    "title": "Hockey DataViz (A5)",
    "section": "Conclusive Figure",
    "text": "Conclusive Figure\n\nCodeNHLdraftstats &lt;- read.csv(\"NHLdraftstats.csv\")\n\nlibrary(ggplot2)\n\nElias &lt;- NHLdraftstats %&gt;%\n  filter(name == \"Elias Lindholm\")\n\nggplot(NHLDraft, aes(x=postdraft, y=NHLgames)) +\n  geom_smooth(aes(color=as.factor(round)), se=FALSE, linetype=\"dashed\") +  \n  geom_smooth(data = Elias, aes(x=postdraft, y=NHLgames), se=FALSE, linetype=\"solid\", linewidth=2, color=\"orange\") +\n  labs(title = \"NHL Games by Post-Draft Position + Elias Performance (in orange)\",\n       x = \"Post-Draft Position\",\n       y = \"NHL Games\",\n       color = \"Round\") +\n  theme_minimal()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "posts/Winter Sports/index.html#divergence",
    "href": "posts/Winter Sports/index.html#divergence",
    "title": "Hockey DataViz (A5)",
    "section": "DIVERGENCE",
    "text": "DIVERGENCE\nEnough esoteric wandering. The original version of this assignment focused on the relative value of draft picks in the NHL. This version has a more specific question. What might picks in the range of pick 31 conceivably yield? How often do picks in that range yield players of Elias Lindholm’s value?\nI guess we’d better figure out what Elias Lindholm brings to the table.\nCan you find him in our existing data? Can you think of a way to highlight him in the context of number of games played? What other kinds of data might we need to fairly evaluate Lindholm and pick 31?\nYou will be surprised how these seemingly simple questions force you to explore the nuances of working with and visualizing tabular data."
  },
  {
    "objectID": "posts/Winter Sports/index.html#conclusion",
    "href": "posts/Winter Sports/index.html#conclusion",
    "title": "Hockey DataViz (A5)",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nBased on your visualizations, what would you advise regarding this trade proposal? Why?\nClearly, Elias Lindholm is an above average player, as shown it the graph above (NHL Games by Post-Draft Position + Elias Performance (in orange)). His rental should provide an immediate boost to the Canucks, considering his performance and experience. The trade seems favorable in the present. It’s important to consider that the chances for a pick 31 player to be extraordinary are extremely slim, so this supports the trade in favor of the Canucks."
  },
  {
    "objectID": "posts/Network Data/index.html",
    "href": "posts/Network Data/index.html",
    "title": "Network Data",
    "section": "",
    "text": "In this assignment, we’ll consider some of the tools and techniques for visualizing network data. Network data is characterized by two unique items that are not found in tabular or spatial data - Nodes and Links. In addition, there is a sub-type of network data that we will consider - Hierarchical or Tree data. Let’s practice a few visualizations to get a feel for how these things work!"
  },
  {
    "objectID": "posts/Network Data/index.html#igraph",
    "href": "posts/Network Data/index.html#igraph",
    "title": "Network Data",
    "section": "IGRAPH",
    "text": "IGRAPH\nLet’s start with igraph, which is an open source toolset for network analysis. The great thing about igraph is that you can use these tools in R, Python, Mathematica, and C++. It is very flexible and very powerful.\n\nigraph in R\nFirst up, we’ll install R/igraph and load the library (note that I’ve commented out the package installation because I’ve already installed igraph on my machine):\n\n\nCode\n# install.packages(\"igraph\")\nlibrary(igraph)\n\n\nWarning: package 'igraph' was built under R version 4.2.3\n\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\n\nNow I’m going to walk you through a modified version of the igraph tutorial, which you can find here"
  },
  {
    "objectID": "posts/Network Data/index.html#creating-a-graph",
    "href": "posts/Network Data/index.html#creating-a-graph",
    "title": "Network Data",
    "section": "Creating a graph",
    "text": "Creating a graph\nigraph offers many ways to create a graph. The simplest one is the function make_empty_graph:\n\n\nCode\ng &lt;- make_empty_graph()\n\n\nThe most common way to create a graph is make_graph, which constructs a network based on specified edges. For example, to make a graph with 10 nodes (numbered 1 to 10) and two edges connecting nodes 1-2 and 1-5:\n\n\nCode\ng &lt;- make_graph(edges = c(1,2, 1,5), n=10, directed = FALSE)\n\n\nWe can print the graph to get a summary of its nodes and edges:\n\n\nCode\ng\n\n\nIGRAPH 029ba61 U--- 10 2 -- \n+ edges from 029ba61:\n[1] 1--2 1--5\n\n\nThis means: Undirected Named graph with 10 vertices and 2 edges, with the exact edges listed out. If the graph has a [name] attribute, it is printed as well.\n\n\n\n\n\n\nNote\n\n\n\nsummary does not list the edges, which is convenient for large graphs with millions of edges:\n\n\n\n\nCode\nsummary(g)\n\n\nIGRAPH 029ba61 U--- 10 2 -- \n\n\nThe same function make_graph can create some notable graphs by just specifying their name. For example you can create the graph that represents the social network of Zachary’s karate club, that shows the friendship between 34 members of a karate club at a US university in the 1970s:\n\n\nCode\ng &lt;- make_graph('Zachary')\n\n\nTo visualize a graph you can use plot:\n\n\nCode\nplot(g)"
  },
  {
    "objectID": "posts/Network Data/index.html#vertex-and-edge-ids",
    "href": "posts/Network Data/index.html#vertex-and-edge-ids",
    "title": "Network Data",
    "section": "Vertex and edge IDs",
    "text": "Vertex and edge IDs\nVertices and edges have numerical vertex IDs in igraph. Vertex IDs are always consecutive and they start with 1. For a graph with n vertices the vertex IDs are always between 1 and n. If some operation changes the number of vertices in the graphs, e.g. a subgraph is created via induced_subgraph, then the vertices are renumbered to satisfy this criterion.\nThe same is true for the edges as well: edge IDs are always between 1 and m, the total number of edges in the graph.\nIn addition to IDs, vertices and edges can be assigned a name and other attributes. That makes it easier to track them whenever the graph is altered."
  },
  {
    "objectID": "posts/Network Data/index.html#addingdeleting-vertices-and-edges",
    "href": "posts/Network Data/index.html#addingdeleting-vertices-and-edges",
    "title": "Network Data",
    "section": "Adding/deleting vertices and edges",
    "text": "Adding/deleting vertices and edges\nLet’s continue working with the Karate club graph. To add one or more vertices to an existing graph, use add_vertices:\n\n\nCode\ng &lt;- add_vertices(g, 3)\n\n\nSimilarly, to add edges you can use add_edges:\n\n\nCode\ng &lt;- add_edges(g, edges = c(1,35, 1,36, 34,37))\n\n\nEdges are added by specifying the source and target vertex IDs for each edge. This call added three edges, one connecting vertices 1 and 35, one connecting vertices 1 and 36, and one connecting vertices 34 and 37.\nIn addition to the add_vertices and add_edges functions, the plus operator can be used to add vertices or edges to graph. The actual operation that is performed depends on the type of the right hand side argument:\n\n\nCode\ng &lt;- g + edges(c(1,35, 1,36, 34,37))\n\n\nYou can add a single vertex/edge at a time using add_vertex and add_edge.\nLet us add some more vertices and edges to our graph. In igraph we can use the magrittr package, which provides a mechanism for chaining commands with the operator %\\&gt;%:\n\n\nCode\ng &lt;- g %&gt;% add_edges(edges=c(1,34)) %&gt;% add_vertices(3) %&gt;%\n     add_edges(edges=c(38,39, 39,40, 40,38, 40,37))\ng\n\n\nIGRAPH fcfd723 U--- 40 86 -- Zachary\n+ attr: name (g/c)\n+ edges from fcfd723:\n [1]  1-- 2  1-- 3  1-- 4  1-- 5  1-- 6  1-- 7  1-- 8  1-- 9  1--11  1--12\n[11]  1--13  1--14  1--18  1--20  1--22  1--32  2-- 3  2-- 4  2-- 8  2--14\n[21]  2--18  2--20  2--22  2--31  3-- 4  3-- 8  3--28  3--29  3--33  3--10\n[31]  3-- 9  3--14  4-- 8  4--13  4--14  5-- 7  5--11  6-- 7  6--11  6--17\n[41]  7--17  9--31  9--33  9--34 10--34 14--34 15--33 15--34 16--33 16--34\n[51] 19--33 19--34 20--34 21--33 21--34 23--33 23--34 24--26 24--28 24--33\n[61] 24--34 24--30 25--26 25--28 25--32 26--32 27--30 27--34 28--34 29--32\n[71] 29--34 30--33 30--34 31--33 31--34 32--33 32--34 33--34  1--35  1--36\n+ ... omitted several edges\n\n\nCode\nplot(g)\n\n\n\n\n\nWe now have an undirected graph with 40 vertices and 86 edges. Vertex and edge IDs are always contiguous, so if you delete a vertex all subsequent vertices will be renumbered. When a vertex is renumbered, edges are not renumbered, but their source and target vertices will be. Use delete_vertices and delete_edges to perform these operations. For instance, to delete the edge connecting vertices 1-34, get its ID and then delete it:\n\n\nCode\nget.edge.ids(g, c(1,34))\n\n\n[1] 82\n\n\n\n\nCode\ng &lt;- delete_edges(g, 82)\n\n\nAs an example, to create a broken ring:\n\n\nCode\ng &lt;- make_ring(10) %&gt;% delete_edges(\"10|1\")\nplot(g)\n\n\n\n\n\nThe example above shows that you can also refer to edges with strings containing the IDs of the source and target vertices, connected by a pipe symbol |. \"10|1\" in the above example means the edge that connects vertex 10 to vertex 1. Of course you can also use the edge IDs directly, or retrieve them with the get.edge.ids function:\n\n\nCode\ng &lt;- make_ring(5)\ng &lt;- delete_edges(g, get.edge.ids(g, c(1,5, 4,5)))\nplot(g)"
  },
  {
    "objectID": "posts/Network Data/index.html#constructing-graphs",
    "href": "posts/Network Data/index.html#constructing-graphs",
    "title": "Network Data",
    "section": "Constructing graphs",
    "text": "Constructing graphs\nIn addition to make_empty_graph, make_graph, and make_graph_from_literal, igraph includes many other function to construct a graph. Some are deterministic, i.e. they produce the same graph each single time, e.g. make_tree:\n\n\nCode\ngraph1 &lt;- make_tree(127, 2, mode = \"undirected\")\nsummary(graph1)\n\n\nIGRAPH 44785af U--- 127 126 -- Tree\n+ attr: name (g/c), children (g/n), mode (g/c)\n\n\nCode\nplot(graph1)\n\n\n\n\n\nThis generates a regular tree graph with 127 vertices, each vertex having two children. No matter how many times you call make_tree, the generated graph will always be the same if you use the same parameters:\n\n\nCode\ngraph2 &lt;- make_tree(127, 2, mode = \"undirected\")\n\n\n\n\nCode\nidentical_graphs(graph1,graph2)\n\n\n[1] TRUE\n\n\nOther functions generate graphs stochastically, i.e. they produce a different graph each time. For instance sample_grg:\n\n\nCode\ngraph1 &lt;- sample_grg(100, 0.2)\nsummary(graph1)\n\n\nIGRAPH 42831f1 U--- 100 501 -- Geometric random graph\n+ attr: name (g/c), radius (g/n), torus (g/l)\n\n\nCode\nplot(graph1)\n\n\n\n\n\nThis generates a geometric random graph: n points are chosen randomly and uniformly inside the unit square and pairs of points closer to each other than a predefined distance d are connected by an edge. If you generate GRGs with the same parameters, they will be different:\n\n\nCode\ngraph2 &lt;- sample_grg(100, 0.2)\nidentical_graphs(graph1, graph2)\n\n\n[1] FALSE\n\n\nCode\nplot(graph2)\n\n\n\n\n\nA slightly looser way to check if the graphs are equivalent is via isomorphic. Two graphs are said to be isomorphic if they have the same number of components (vertices and edges) and maintain a one-to-one correspondence between vertices and edges, i.e., they are connected in the same way.\n\n\nCode\nisomorphic(graph1, graph2)\n\n\n[1] FALSE\n\n\nChecking for isomorphism can take a while for large graphs (in this case, the answer can quickly be given by checking the degree sequence of the two graphs). identical_graph is a stricter criterion than isomorphic: the two graphs must have the same list of vertices and edges, in exactly the same order, with same directedness, and the two graphs must also have identical graph, vertex and edge attributes."
  },
  {
    "objectID": "posts/Network Data/index.html#setting-and-retrieving-attributes",
    "href": "posts/Network Data/index.html#setting-and-retrieving-attributes",
    "title": "Network Data",
    "section": "Setting and retrieving attributes",
    "text": "Setting and retrieving attributes\nIn addition to IDs, vertex and edges can have attributes such as a name, coordinates for plotting, metadata, and weights. The graph itself can have such attributes too (e.g. a name, which will show in summary). In a sense, every graph, vertex and edge can be used as an R namespace to store and retrieve these attributes.\nTo demonstrate the use of attributes, let us create a simple social network:\n\n\nCode\ng &lt;- make_graph(~ Alice-Bob:Claire:Frank, Claire-Alice:Dennis:Frank:Esther,\n                George-Dennis:Frank, Dennis-Esther)\n\n\nEach vertex represents a person, so we want to store ages, genders and types of connection between two people (is_formal refers to whether a connection between one person or another is formal or informal, i.e. colleagues or friends). The \\$ operator is a shortcut to get and set graph attributes. It is shorter and just as readable as graph_attr and set_graph_attr.\n\n\nCode\nV(g)$age &lt;- c(25, 31, 18, 23, 47, 22, 50) \nV(g)$gender &lt;- c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")\nE(g)$is_formal &lt;- c(FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE)\nsummary(g)\n\n\nIGRAPH 11d581b UN-- 7 9 -- \n+ attr: name (v/c), age (v/n), gender (v/c), is_formal (e/l)\n\n\nV and E are the standard way to obtain a sequence of all vertices and edges, respectively. This assigns an attribute to all vertices/edges at once. Another way to generate our social network is with the use of set_vertex_attr and set_edge_attr and the operator %\\&gt;%:\n\n\nCode\ng &lt;- make_graph(~ Alice-Bob:Claire:Frank, Claire-Alice:Dennis:Frank:Esther,\n                George-Dennis:Frank, Dennis-Esther) %&gt;%\n  set_vertex_attr(\"age\", value = c(25, 31, 18, 23, 47, 22, 50)) %&gt;%\n  set_vertex_attr(\"gender\", value = c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")) %&gt;%\n  set_edge_attr(\"is_formal\", value = c(FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE))\nsummary(g)\n\n\nTo assign or modify an attribute for a single vertex/edge:\n\n\nCode\nE(g)$is_formal\n\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n\nCode\nE(g)$is_formal[1] &lt;- TRUE\nE(g)$is_formal\n\n\n[1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n\nAttribute values can be set to any R object, but note that storing the graph in some file formats might result in the loss of complex attribute values. Vertices, edges and the graph itself can all be used to set attributes, e.g. to add a date to the graph:\n\n\nCode\ng$date &lt;- c(\"2022-02-11\")\ngraph_attr(g, \"date\")\n\n\n[1] \"2022-02-11\"\n\n\nTo retrieve attributes, you can also use graph_attr, vertex_attr, and edge_attr. To find the ID of a vertex you can use the function match:\n\n\nCode\nmatch(c(\"George\"), V(g)$name)\n\n\n[1] 7\n\n\nTo assign attributes to a subset of vertices or edges, you can use:\n\n\nCode\nV(g)$name[1:3] &lt;- c(\"Alejandra\", \"Bruno\", \"Carmina\")\nV(g)\n\n\n+ 7/7 vertices, named, from 11d581b:\n[1] Alejandra Bruno     Carmina   Frank     Dennis    Esther    George   \n\n\nTo delete attributes:\n\n\nCode\ng &lt;- delete_vertex_attr(g, \"gender\")\nV(g)$gender\n\n\nNULL\n\n\nIf you want to save a graph in R with all the attributes use the R’s standard function dput function and retrieve it later with dget. You can also just save the R workspace and restore it later."
  },
  {
    "objectID": "posts/Network Data/index.html#structural-properties-of-graphs",
    "href": "posts/Network Data/index.html#structural-properties-of-graphs",
    "title": "Network Data",
    "section": "Structural properties of graphs",
    "text": "Structural properties of graphs\nigraph provides a large set of functions to calculate various structural properties of graphs. It is beyond the scope of this tutorial to document all of them, hence this section will only introduce a few of them for illustrative purposes. We will work on the small social network constructed in the previous section.\nPerhaps the simplest property one can think of is the degree. The degree of a vertex equals the number of edges adjacent to it. In case of directed networks, we can also define in-degree (the number of edges pointing towards the vertex) and out-degree (the number of edges originating from the vertex). igraph is able to calculate all of them using a simple syntax:\n\n\nCode\ndegree(g)\n\n\nAlejandra     Bruno   Carmina     Frank    Dennis    Esther    George \n        3         1         4         3         3         2         2 \n\n\nIf the graph was directed, we would have been able to calculate the in- and out-degrees separately using degree(mode=\"in\") and degree(mode=\"out\"). You can also pass a single vertex ID or a list of vertex IDs to degree if you want to calculate the degrees for only a subset of vertices:\n\n\nCode\ndegree(g, 7)\n\n\nGeorge \n     2 \n\n\n\n\nCode\ndegree(g, v=c(3,4,5))\n\n\nCarmina   Frank  Dennis \n      4       3       3 \n\n\nMost functions that accept vertex IDs also accept vertex names (i.e. the values of the name vertex attribute) as long as the names are unique:\n\n\nCode\ndegree(g, v=c(\"Carmina\", \"Frank\", \"Dennis\"))\n\n\nCarmina   Frank  Dennis \n      4       3       3 \n\n\nIt also works for single vertices:\n\n\nCode\ndegree(g, \"Bruno\")\n\n\nBruno \n    1 \n\n\nA similar syntax is used for most of the structural properties igraph can calculate. For vertex properties, the functions accept a vertex ID, a vertex name, or a list of vertex IDs or names (and if they are omitted, the default is the set of all vertices). For edge properties, the functions accept a single edge ID or a list of edge IDs.\n\nNOTE: For some measures, it does not make sense to calculate them only for a few vertices or edges instead of the whole graph, as it would take the same time anyway. In this case, the functions won’t accept vertex or edge IDs, but you can still restrict the resulting list later using standard operations. One such example is eigenvector centrality (evcent()).\n\nBesides degree, igraph includes built-in routines to calculate many other centrality properties, including vertex and edge betweenness (edge_betweenness) or Google’s PageRank (page_rank) just to name a few. Here we just illustrate edge betweenness:\n\n\nCode\nedge_betweenness(g)\n\n\n[1] 6 6 4 3 4 4 4 2 3\n\n\nNow we can also figure out which connections have the highest betweenness centrality:\n\n\nCode\nebs &lt;- edge_betweenness(g)\nas_edgelist(g)[ebs == max(ebs), ]\n\n\n     [,1]        [,2]     \n[1,] \"Alejandra\" \"Bruno\"  \n[2,] \"Alejandra\" \"Carmina\""
  },
  {
    "objectID": "posts/Network Data/index.html#querying-vertices-and-edges-based-on-attributes",
    "href": "posts/Network Data/index.html#querying-vertices-and-edges-based-on-attributes",
    "title": "Network Data",
    "section": "Querying vertices and edges based on attributes",
    "text": "Querying vertices and edges based on attributes\n\nSelecting vertices\nImagine that in a given social network, you want to find out who has the largest degree. You can do that with the tools presented so far and the which.max function:\n\n\nCode\nwhich.max(degree(g))\n\n\nCarmina \n      3 \n\n\nAnother example would be to select only vertices that have only odd IDs but not even ones, using the V function:\n\n\nCode\ngraph &lt;- graph.full(n=10)\nonly_odd_vertices &lt;- which(V(graph)%%2==1)\nlength(only_odd_vertices)\n\n\n[1] 5\n\n\nOf course, it is possible to select vertices or edges by positional indices:\n\n\nCode\nseq &lt;- V(graph)[2, 3, 7]\nseq\n\n\n+ 3/10 vertices, from 17b5282:\n[1] 2 3 7\n\n\n\n\nCode\nseq &lt;- seq[1, 3]    # filtering an existing vertex set\nseq\n\n\n+ 2/10 vertices, from 17b5282:\n[1] 2 7\n\n\nSelecting a vertex that does not exist results in an error:\n\n\nCode\nseq &lt;- V(graph)[2, 3, 7, \"foo\", 3.5]\n## Error in simple_vs_index(x, ii, na_ok) : Unknown vertex selected\n\n\nAttribute names can also be used as-is within the indexing brackets of V() and E(). This can be combined with R’s ability to use boolean vectors for indexing to obtain very concise and readable expressions to retrieve a subset of the vertex or edge set of a graph. For instance, the following command gives you the names of the individuals younger than 30 years in our social network:\n\n\nCode\nV(g)[age &lt; 30]$name\n\n\n[1] \"Alejandra\" \"Carmina\"   \"Frank\"     \"Esther\"   \n\n\nOf course, &lt; is not the only boolean operator that can be used for this. Other possibilities include the following:\n\n\n\n\n\n\n\nOperator\nMeaning\n\n\n\n\n==\nThe attribute/property value must be equal to\n\n\n!=\nThe attribute/property value must not be equal to\n\n\n&lt;\nThe attribute/property value must be less than\n\n\n&lt;=\nThe attribute/property value must be less than or equal to\n\n\n&gt;\nThe attribute/property value must be greater than\n\n\n&gt;=\nThe attribute/property value must be greater than or equal to\n\n\n%in%\nThe attribute/property value must be included in\n\n\n\nYou can also create a “not in” operator from %in% using the Negate function:\n\n\nCode\n`%notin%` &lt;- Negate(`%in%`)\n\n\nIf an attribute has the same name as an igraph function, you should be careful as the syntax can become a little confusing. For instance, if there is an attribute named degree that represents the grades of an exam for each person, that should not be confused with the igraph function that computes the degrees of vertices in a network sense:\n\n\nCode\nV(g)$degree &lt;- c(\"A\", \"B\", \"B+\", \"A+\", \"C\", \"A\", \"B\")\nV(g)$degree[degree(g) == 3]\n\n\n[1] \"A\"  \"A+\" \"C\" \n\n\n\n\nCode\nV(g)$name[degree(g) == 3]\n\n\n[1] \"Alejandra\" \"Frank\"     \"Dennis\"   \n\n\n\n\nSelecting edges\nEdges can be selected based on attributes just like vertices. As mentioned above, the standard way to get edges is E. Moreover, there are a few special structural properties for selecting edges.\nUsing .from allows you to filter the edge sequence based on the source vertices of the edges. E.g., to select all the edges originating from Carmina (who has vertex index 3):\n\n\nCode\nE(g)[.from(3)]\n\n\n+ 4/9 edges from 11d581b (vertex names):\n[1] Alejandra--Carmina Carmina  --Frank   Carmina  --Dennis  Carmina  --Esther \n\n\nOf course it also works with vertex names:\n\n\nCode\nE(g)[.from(\"Carmina\")]\n\n\n+ 4/9 edges from 11d581b (vertex names):\n[1] Alejandra--Carmina Carmina  --Frank   Carmina  --Dennis  Carmina  --Esther \n\n\nUsing .to filters edge sequences based on the target vertices. This is different from .from if the graph is directed, while it gives the same answer for undirected graphs. Using .inc selects only those edges that are incident on a single vertex or at least one of the vertices, irrespectively of the edge directions.\nThe %--% operator can be used to select edges between specific groups of vertices, ignoring edge directions in directed graphs. For instance, the following expression selects all the edges between Carmina (vertex index 3), Dennis (vertex index 5) and Esther (vertex index 6):\n\n\nCode\nE(g) [ 3:5 %--% 5:6 ]\n\n\n+ 3/9 edges from 11d581b (vertex names):\n[1] Carmina--Dennis Carmina--Esther Dennis --Esther\n\n\nTo make the %--% operator work with names, you can build string vectors containing the names and then use these vectors as operands. For instance, to select all the edges that connect men to women, we can do the following after re-adding the gender attribute that we deleted earlier:\n\n\nCode\nV(g)$gender &lt;- c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")\n\n\n\n\nCode\nmen &lt;- V(g)[gender == \"m\"]$name\nmen\n\n\n[1] \"Bruno\"  \"Frank\"  \"Dennis\" \"George\"\n\n\n\n\nCode\nwomen &lt;- V(g)[gender == \"f\"]$name\nwomen\n\n\n[1] \"Alejandra\" \"Carmina\"   \"Esther\"   \n\n\n\n\nCode\nE(g)[men %--% women]\n\n\n+ 5/9 edges from 11d581b (vertex names):\n[1] Alejandra--Bruno  Alejandra--Frank  Carmina  --Frank  Carmina  --Dennis\n[5] Dennis   --Esther"
  },
  {
    "objectID": "posts/Network Data/index.html#treating-a-graph-as-an-adjacency-matrix",
    "href": "posts/Network Data/index.html#treating-a-graph-as-an-adjacency-matrix",
    "title": "Network Data",
    "section": "Treating a graph as an adjacency matrix",
    "text": "Treating a graph as an adjacency matrix\nThe adjacency matrix is another way to represent a graph. In an adjacency matrix, rows and columns are labeled by graph vertices, and the elements of the matrix indicate the number of edges between vertices i and j. The adjacency matrix for the example graph is:\n\n\nCode\nget.adjacency(g)\n\n\nWarning: `get.adjacency()` was deprecated in igraph 2.0.0.\nℹ Please use `as_adjacency_matrix()` instead.\n\n\n7 x 7 sparse Matrix of class \"dgCMatrix\"\n          Alejandra Bruno Carmina Frank Dennis Esther George\nAlejandra         .     1       1     1      .      .      .\nBruno             1     .       .     .      .      .      .\nCarmina           1     .       .     1      1      1      .\nFrank             1     .       1     .      .      .      1\nDennis            .     .       1     .      .      1      1\nEsther            .     .       1     .      1      .      .\nGeorge            .     .       .     1      1      .      .\n\n\nFor example, Carmina (1, 0, 0, 1, 1, 1, 0) is directly connected to Alejandra (who has vertex index 1), Frank (index 4), Dennis (index 5) and Esther (index 6), but not to Bruno (index 2) or to George (index 7)."
  },
  {
    "objectID": "posts/Network Data/index.html#layouts-and-plotting",
    "href": "posts/Network Data/index.html#layouts-and-plotting",
    "title": "Network Data",
    "section": "Layouts and plotting",
    "text": "Layouts and plotting\nA graph is an abstract mathematical object without a specific representation in 2D, 3D or any other geometric space. This means that whenever we want to visualise a graph, we have to find a mapping from vertices to coordinates in two- or three-dimensional space first, preferably in a way that is useful and/or pleasing for the eye. A separate branch of graph theory, namely graph drawing, tries to solve this problem via several graph layout algorithms. igraph implements quite a few layout algorithms and is also able to draw them onto the screen or to any output format that R itself supports.\n\nLayout algorithms\nThe layout functions in igraph always start with layout. The following table summarises them:\n\n\n\n\n\n\n\nMethod name\nAlgorithm description\n\n\n\n\nlayout_randomly\nPlaces the vertices completely randomly\n\n\nlayout_in_circle\nDeterministic layout that places the vertices on a circle\n\n\nlayout_on_sphere\nDeterministic layout that places the vertices evenly on the surface of a sphere\n\n\nlayout_with_drl\nThe Drl (Distributed Recursive Layout) algorithm for large graphs\n\n\nlayout_with_fr\nFruchterman-Reingold force-directed algorithm\n\n\nlayout_with_kk\nKamada-Kawai force-directed algorithm\n\n\nlayout_with_lgl\nThe LGL (Large Graph Layout) algorithm for large graphs\n\n\nlayout_as_tree\nReingold-Tilford tree layout, useful for (almost) tree-like graphs\n\n\nlayout_nicely\nLayout algorithm that automatically picks one of the other algorithms based on certain properties of the graph\n\n\n\nLayout algorithms can be called directly with a graph as its first argument. They will return a matrix with two columns and as many rows as the number of vertices in the graph; each row will correspond to the position of a single vertex, ordered by vertex IDs. Some algorithms have a 3D variant; in this case they return three columns instead of 2.\n\n\nCode\nlayout &lt;- layout_with_kk(g)\n\n\nSome layout algorithms take additional arguments; e.g., when laying out a graph as a tree, it might make sense to specify which vertex is to be placed at the root of the layout:\n\n\nCode\nlayout &lt;- layout_as_tree(g, root = 2)\n\n\n\n\nDrawing a graph using a layout\nWe can plot our imaginary social network with the Kamada-Kawai layout algorithm as follows:\n\n\nCode\nlayout &lt;- layout_with_kk(g)\n\n\n\n\nCode\nplot(g, layout = layout, main = \"Social network with the Kamada-Kawai layout algorithm\")\n\n\n\n\n\nThis should open a new window showing a visual representation of the network. Remember that the exact placement of nodes may be different on your machine since the layout is not deterministic.\nThe layout argument also accepts functions; in this case, the function will be called with the graph as its first argument. This makes it possible to just pass the name of a layout function directly, without creating a layout variable:\n\n\nCode\nplot(g, layout = layout_with_fr,\n     main = \"Social network with the Fruchterman-Reingold layout algorithm\")\n\n\n\n\n\nTo improve the visuals, a trivial addition would be to color the vertices according to the gender. We should also try to place the labels slightly outside the vertices to improve readability:\n\n\nCode\nV(g)$color &lt;- ifelse(V(g)$gender == \"m\", \"yellow\", \"red\")\nplot(g, layout = layout, vertex.label.dist = 3.5,\n     main = \"Social network - with genders as colors\")\n\n\n\n\n\nYou can also treat the gender attribute as a factor and provide the colors with an argument to plot(), which takes precedence over the color vertex attribute. Colors will be assigned automatically to levels of a factor:\n\n\nCode\nplot(g, layout=layout, vertex.label.dist=3.5, vertex.color=as.factor(V(g)$gender))\n\n\n\n\n\nAs seen above with the vertex.color argument, you can specify visual properties as arguments to plot instead of using vertex or edge attributes. The following plot shows the formal ties with thick lines while informal ones with thin lines:\n\n\nCode\nplot(g, layout=layout, vertex.label.dist=3.5, vertex.size=20,\n     vertex.color=ifelse(V(g)$gender == \"m\", \"yellow\", \"red\"),\n     edge.width=ifelse(E(g)$is_formal, 5, 1))\n\n\n\n\n\nThis latter approach is preferred if you want to keep the properties of the visual representation of your graph separate from the graph itself.\nIn summary, there are special vertex and edge properties that correspond to the visual representation of the graph. These attributes override the default settings of igraph (i.e color, weight, name, shape,layout,etc.). The following two tables summarise the most frequently used visual attributes for vertices and edges, respectively:\n\n\nVertex attributes controlling graph plots\n\n\n\n\n\n\n\n\nAttribute name\nKeyword argument\nPurpose\n\n\n\n\ncolor\nvertex.color\nColor of the vertex\n\n\nlabel\nvertex.label\nLabel of the vertex. They will be converted to character. Specify NA to omit vertex labels. The default vertex labels are the vertex ids.\n\n\nlabel.cex\nvertex.label.cex\nFont size of the vertex label, interpreted as a multiplicative factor, similarly to R’s text function\n\n\nlabel.color\nvertex.label.color\nColor of the vertex label\n\n\nlabel.degree\nvertex.label.degree\nIt defines the position of the vertex labels, relative to the center of the vertices. It is interpreted as an angle in radian, zero means ‘to the right’, and ‘pi’ means to the left, up is -pi/2 and down is pi/2. The default value is -pi/4\n\n\nlabel.dist\nvertex.label.dist\nDistance of the vertex label from the vertex itself, relative to the vertex size\n\n\nlabel.family\nvertex.label.family\nFont family of the vertex, similarly to R’s text function\n\n\nlabel.font\nvertex.label.font\nFont within the font family of the vertex, similarly to R’s text function\n\n\nshape\nvertex.shape\nThe shape of the vertex, currently “circle”, “square”, “csquare”, “rectangle”, “crectangle”, “vrectangle”, “pie” (see vertex.shape.pie), ‘sphere’, and “none” are supported, and only by the plot.igraph command.\n\n\nsize\nvertex.size\nThe size of the vertex, a numeric scalar or vector, in the latter case each vertex sizes may differ\n\n\n\n\n\nEdge attributes controlling graph plots\n\n\n\n\n\n\n\n\nAttribute name\nKeyword argument\nPurpose\n\n\n\n\ncolor\nedge.color\nColor of the edge\n\n\ncurved\nedge.curved\nA numeric value specifies the curvature of the edge; zero curvature means straight edges, negative values means the edge bends clockwise, positive values the opposite. TRUE means curvature 0.5, FALSE means curvature zero\n\n\narrow.size\nedge.arrow.size\nCurrently this is a constant, so it is the same for every edge. If a vector is submitted then only the first element is used, ie. if this is taken from an edge attribute then only the attribute of the first edge is used for all arrows.\n\n\narrow.width\nedge.arrow.width\nThe width of the arrows. Currently this is a constant, so it is the same for every edge\n\n\nwidth\nedge.width\nWidth of the edge in pixels\n\n\nlabel\nedge.label\nIf specified, it adds a label to the edge.\n\n\nlabel.cex\nedge.label.cex\nFont size of the edge label, interpreted as a multiplicative factor, similarly to R’s text function\n\n\nlabel.color\nedge.label.color\nColor of the edge label\n\n\nlabel.family\nedge.label.family\nFont family of the edge, similarly to R’s text function\n\n\nlabel.font\nedge.label.font\nFont within the font family of the edge, similarly to R’s text function\n\n\n\n\n\nGeneric arguments of plot()\nThese settings can be specified as arguments to the plot function to control the overall appearance of the plot.\n\n\n\n\n\n\n\nKeyword argument\nPurpose\n\n\n\n\nlayout\nThe layout to be used. It can be an instance of Layout, a list of tuples containing X-Y coordinates, or the name of a layout algorithm. The default is auto, which selects a layout algorithm automatically based on the size and connectedness of the graph.\n\n\nmargin\nThe amount of empty space below, over, at the left and right of the plot, it is a numeric vector of length four."
  },
  {
    "objectID": "posts/Network Data/index.html#assignment",
    "href": "posts/Network Data/index.html#assignment",
    "title": "Network Data",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nImprove the network above by:\n\nColoring the edges according to Advisor / BCB520 attribute.\nColoring the nodes according to Department.\nAdujsting the labels to improve readability.\nFind the best layout you can for this garbage. What a nightmare.\n\n\n\nCode\nlibrary(dplyr)\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:igraph':\n\n    as_data_frame, groups, union\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(igraph)\n\n# Assuming 'people' and 'relations' dataframes are defined somewhere above this code\n\nBCB &lt;- people %&gt;%\n  filter(BCB520 == \"TRUE\") %&gt;%\n  select(name, BCB520)\n\nedgelist &lt;- combn(BCB$name, 2)\nedgelist_df &lt;- as.data.frame(t(edgelist))\ncolnames(edgelist_df) &lt;- c(\"from\", \"to\")\nedgelist_df$BCB520 &lt;- \"TRUE\"\nedgelist_df$Advisor &lt;- \"FALSE\"\n\nrelations$BCB520 &lt;- \"FALSE\"\nrelations3 &lt;- rbind(relations, edgelist_df)\n\ng &lt;- graph_from_data_frame(relations3, directed = FALSE, vertices = people)\n\n# Correcting the edge color assignment\nE(g)$color &lt;- ifelse(E(g)$Advisor == \"TRUE\", \"blue\", \"red\")\n\n# Create a color palette for the departments\ndepartment_colors &lt;- setNames(c(\"red\", \"cyan\", \"white\", \"yellow\", \"orange\", \"pink\", \"lightblue\"),\n                              c(\"Biology\", \"EPPN\", \"FCS1\", \"CNR\", \"FCS2\", \"PlantSci\", \"Math\"))\n\n# Map the department of each vertex in the graph to the corresponding color\nV(g)$color &lt;- department_colors[people$department[match(V(g)$name, people$name)]]\n\n# Plot the graph\nplot(g, \n     layout = layout_with_kk(g), \n     vertex.color = V(g)$color, \n     vertex.size = 35,\n     vertex.label.cex = 0.6,\n     vertex.label.color = \"black\",\n     vertex.label.font = 2)\n\n# Adding a legend for departments manually\nlegend(\"topright\",\n       legend = names(department_colors),\n       col = department_colors,\n       pch = 20,\n       cex = 0.8,\n       title = \"Department\",\n       bty = \"n\")"
  },
  {
    "objectID": "posts/Network Data/index.html#section",
    "href": "posts/Network Data/index.html#section",
    "title": "Network Data",
    "section": "",
    "text": "After trying a few different layouts The Kamada-Kawai algorithm seems like the right layout that offers the most straightforward interpretation of the BCB520 network."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "“Welcome!”",
    "section": "",
    "text": "Green lacewing family Chrysopidae"
  },
  {
    "objectID": "posts/MarksChannels/index.html",
    "href": "posts/MarksChannels/index.html",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "Code\nlibrary(readxl)\nWeevils &lt;- read_excel(\"~/Mi unidad/Uidaho/Clases/PhD/Spring 2024/BCB 520/Data/Weevils.xlsx\")\nhead(Weevils)\n\n\n# A tibble: 6 × 9\n  Treatment Replicate `Insecticide Name` Before `7 dpa` `14 dpa` `21 dpa`\n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1         0         1 Control                11       3        5        2\n2         0         2 Control                 4       4        4        3\n3         0         3 Control                16       6        7        3\n4         0         4 Control                 5       3        1        3\n5         0         5 Control                10       6        7        4\n6         0         6 Control                 2       5        2        4\n# ℹ 2 more variables: `28 dpa` &lt;dbl&gt;, `35 dpa` &lt;dbl&gt;\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nBmeans &lt;-Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE), AVG2 = mean(`14 dpa`, na.rm = TRUE), AVG3 = mean(`21 dpa`, na.rm = TRUE), AVG4 = mean(`28 dpa`, na.rm = TRUE), AVG5 = mean(`35 dpa`, na.rm = TRUE) )\nlibrary(ggplot2)\n\n\n\n\n\nThis figure uses different colors to make clear the difference between treatments. As the concentration of the experimental sample increases, the hue of the blue color increases as well making sense (to me).\n\n\n\n\n\nCode\nlibrary(tidyverse)\nBmeans &lt;-Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE), AVG2 = mean(`14 dpa`, na.rm = TRUE), AVG3 = mean(`21 dpa`, na.rm = TRUE), AVG4 = mean(`28 dpa`, na.rm = TRUE), AVG5 = mean(`35 dpa`, na.rm = TRUE) )\nlibrary(ggplot2)\nmy_colors &lt;- c(\"green\", \"cyan\", \"blue\", \"darkblue\", \"gold\", \"black\")\n\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant before treatments\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\nThis figure violates the channel correct use, since it uses the same color for every treatment, still is possible to understand what is going on but it takes significantly more time.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG)) +\n  geom_bar(stat = \"identity\", fill = \"black\") +\n  labs(title = \"Mean weevils per plant before treatments\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#section",
    "href": "posts/MarksChannels/index.html#section",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "Code\nlibrary(readxl)\nWeevils &lt;- read_excel(\"~/Mi unidad/Uidaho/Clases/PhD/Spring 2024/BCB 520/Data/Weevils.xlsx\")\nhead(Weevils)\n\n\n# A tibble: 6 × 9\n  Treatment Replicate `Insecticide Name` Before `7 dpa` `14 dpa` `21 dpa`\n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1         0         1 Control                11       3        5        2\n2         0         2 Control                 4       4        4        3\n3         0         3 Control                16       6        7        3\n4         0         4 Control                 5       3        1        3\n5         0         5 Control                10       6        7        4\n6         0         6 Control                 2       5        2        4\n# ℹ 2 more variables: `28 dpa` &lt;dbl&gt;, `35 dpa` &lt;dbl&gt;\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nBmeans &lt;-Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE), AVG2 = mean(`14 dpa`, na.rm = TRUE), AVG3 = mean(`21 dpa`, na.rm = TRUE), AVG4 = mean(`28 dpa`, na.rm = TRUE), AVG5 = mean(`35 dpa`, na.rm = TRUE) )\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-1",
    "href": "posts/MarksChannels/index.html#figure-1",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "This figure uses different colors to make clear the difference between treatments. As the concentration of the experimental sample increases, the hue of the blue color increases as well making sense (to me)."
  },
  {
    "objectID": "posts/MarksChannels/index.html#section-1",
    "href": "posts/MarksChannels/index.html#section-1",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nBmeans &lt;-Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE), AVG2 = mean(`14 dpa`, na.rm = TRUE), AVG3 = mean(`21 dpa`, na.rm = TRUE), AVG4 = mean(`28 dpa`, na.rm = TRUE), AVG5 = mean(`35 dpa`, na.rm = TRUE) )\nlibrary(ggplot2)\nmy_colors &lt;- c(\"green\", \"cyan\", \"blue\", \"darkblue\", \"gold\", \"black\")\n\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant before treatments\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-2",
    "href": "posts/MarksChannels/index.html#figure-2",
    "title": "“ASSIGNMENT 4”",
    "section": "",
    "text": "This figure violates the channel correct use, since it uses the same color for every treatment, still is possible to understand what is going on but it takes significantly more time.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG)) +\n  geom_bar(stat = \"identity\", fill = \"black\") +\n  labs(title = \"Mean weevils per plant before treatments\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-3",
    "href": "posts/MarksChannels/index.html#figure-3",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 3",
    "text": "Figure 3\nThis figure uses different colors and marks (dots) to make clear the difference between treatments.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG5, group = 1, color = `Insecticide Name`)) +\n  geom_line() +\n  geom_point() + # Adds points to the line graph for clarity\n  scale_color_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant 35 DPA\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-4",
    "href": "posts/MarksChannels/index.html#figure-4",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 4",
    "text": "Figure 4\nA thick line, no color difference, no marks in between treatments, makes difficult to separate them. Same channel for everything.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG5, group = 1)) +\n  geom_line(size = 30, color = \"black\") \n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nCode\n  labs(title = \"Mean weevils per plant 35 DPA\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))\n\n\nNULL"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-5",
    "href": "posts/MarksChannels/index.html#figure-5",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 5",
    "text": "Figure 5\nStandard Error of the Mean (SEM), and bars for each treatment are presented using different channels. They are easily distinguishable between each other.\n\n\nCode\nlibrary(tidyverse)\nBmeans &lt;- Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE),\n            AVG2 = mean(`14 dpa`, na.rm = TRUE),\n            AVG3 = mean(`21 dpa`, na.rm = TRUE),\n            AVG4 = mean(`28 dpa`, na.rm = TRUE),\n            AVG5 = mean(`35 dpa`, na.rm = TRUE),\n            SD_14dpa = sd(`14 dpa`, na.rm = TRUE), \n            N_14dpa = sum(!is.na(`14 dpa`))) %&gt;% \n  mutate(SEM_14dpa = SD_14dpa / sqrt(N_14dpa)) \nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG2, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = AVG2 - SEM_14dpa, ymax = AVG2 + SEM_14dpa), width = 0.2) +\n  scale_fill_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant at 14 dpa\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-6",
    "href": "posts/MarksChannels/index.html#figure-6",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 6",
    "text": "Figure 6\nStandard Error of the Mean (SEM), and bars for each treatment shares the same channels. They are hardly distinguishable between each other.\n\n\nCode\nlibrary(tidyverse)\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG2, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = AVG2 - SEM_14dpa, ymax = AVG2 + SEM_14dpa, color = `Insecticide Name`), \n                width = 1, size = 3) +\n  scale_fill_manual(values = my_colors) +\n  scale_color_manual(values = my_colors) + \n  labs(title = \"Mean weevils per plant at 14 dpa\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-7",
    "href": "posts/MarksChannels/index.html#figure-7",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 7",
    "text": "Figure 7\nAs we compare the insecticide treatments with the control, this figure clearly depicts the differences between them and the control, using different channels,\n\n\nCode\nlibrary(tidyverse)\n\nBmeans &lt;- Weevils %&gt;%\n  group_by(`Insecticide Name`) %&gt;%\n  summarise(AVG = mean(Before),\n            AVG1 = mean(`7 dpa`, na.rm = TRUE),\n            AVG2 = mean(`14 dpa`, na.rm = TRUE),\n            AVG3 = mean(`21 dpa`, na.rm = TRUE),\n            AVG4 = mean(`28 dpa`, na.rm = TRUE),\n            AVG5 = mean(`35 dpa`, na.rm = TRUE),\n            SD_35dpa = sd(`35 dpa`, na.rm = TRUE),  # Calculate SD for 35 dpa\n            N_35dpa = sum(!is.na(`35 dpa`))) %&gt;%  # Count non-NA values for 35 dpa\n  mutate(SEM_35dpa = SD_35dpa / sqrt(N_35dpa))  # Calculate SEM for 35 dpa\n\n# Assuming my_colors is already defined\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG5, fill = `Insecticide Name`)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = AVG5 - SEM_35dpa, ymax = AVG5 + SEM_35dpa), width = 0.2) +\n  scale_fill_manual(values = my_colors) +\n  labs(title = \"Mean weevils per plant at 35 dpa\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "posts/MarksChannels/index.html#figure-8",
    "href": "posts/MarksChannels/index.html#figure-8",
    "title": "“ASSIGNMENT 4”",
    "section": "Figure 8",
    "text": "Figure 8\nHere, I’m using the same data at 35 dpa, but the scale of the Y-axis is incorrect. The same channels are used for everything without any markers for separability, resulting in an awful graph.\n\n\nCode\nggplot(Bmeans, aes(x = `Insecticide Name`, y = AVG5, group = 1)) +\n  geom_line(size = 15, color = \"black\") +  # Adjust line size to a reasonable value\n  scale_y_continuous(limits = c(NA, 50)) + # Set the upper limit of y-axis to 50\n  labs(title = \"Mean weevils per plant 35 DPA\",\n       x = \"Insecticides\",\n       y = \"Mean weevils/Plant\") +\n  theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust = 1))"
  }
]